{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sentiment_final.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7d991--97s6M","colab_type":"code","colab":{}},"source":["# 1.) function for reading data and formatting\n","\n","def read_file(file_name): \n","    data_list  = []\n","    with open(file_name, 'r') as f: \n","        for line in f: \n","            line = line.strip() \n","            label = ' '.join(line[1:line.find(\"]\")].strip().split())\n","            text = line[line.find(\"]\")+1:].strip()\n","            data_list.append([label, text])\n","    return data_list "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KX5nWNFt8Tv8","colab_type":"code","colab":{}},"source":["# file path\n","\n","file_name = \"../content/psychExp.txt\"\n","psychExp_txt = read_file(file_name)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hrq5jLiB9b1x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"361c343b-d7d9-40a9-97fc-23df7632e0ee","executionInfo":{"status":"ok","timestamp":1558437606742,"user_tz":-330,"elapsed":2526,"user":{"displayName":"GAGAN SINGH SAINI","photoUrl":"","userId":"08621075158641464912"}}},"source":["print('Total no. of instances: {}'.format(len(psychExp_txt)))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Total no. of instances: 7480\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mbzMka0m9iMK","colab_type":"code","colab":{}},"source":["# method for converting labels from one hot to classes\n","\n","def convert_label(item, name): \n","    items = list(map(float, item.split()))\n","    label = \"\"\n","    for idx in range(len(items)): \n","        if items[idx] == 1: \n","            label += name[idx] + \" \"\n","    \n","    return label.strip()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IqWMWTPg9yUZ","colab_type":"code","colab":{}},"source":["# classes\n","\n","emotions = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EGNK_nnJ92kL","colab_type":"code","colab":{}},"source":["X_all = []\n","y_all = []\n","for label, text in psychExp_txt:\n","    X_all.append(text.lower())\n","    y_all.append(convert_label(label, emotions))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pRcy55bR-HEj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"75876a8c-1b9a-45b0-c728-c902eac9a797","executionInfo":{"status":"ok","timestamp":1558437608786,"user_tz":-330,"elapsed":4528,"user":{"displayName":"GAGAN SINGH SAINI","photoUrl":"","userId":"08621075158641464912"}}},"source":["# Data processing\n","\n","from string import punctuation\n","print('punctuations to be removed: {}'.format(punctuation))\n","\n","X_all_pro = []\n","for text in X_all:\n","    all_text = ''.join([c for c in text if c not in punctuation])\n","    X_all_pro.append(all_text)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["punctuations to be removed: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tKpeKerW-IIS","colab_type":"code","colab":{}},"source":["# Tokenize — Create Vocab to Int mapping dictionary\n","\n","from collections import Counter\n","all_text2 = ' '.join(X_all_pro)\n","# create a list of words\n","words = all_text2.split()\n","# Count all the words using Counter Method\n","count_words = Counter(words)\n","\n","total_words = len(words)\n","sorted_words = count_words.most_common(total_words)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zUTahaws-QxQ","colab_type":"code","colab":{}},"source":["# vocab to integer mapping dictionary with starting index 1\n","\n","vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iVnXDeP7-Uni","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"3adb8776-6bcb-4be8-f3ae-3087baa6d1f9","executionInfo":{"status":"ok","timestamp":1558437608793,"user_tz":-330,"elapsed":4505,"user":{"displayName":"GAGAN SINGH SAINI","photoUrl":"","userId":"08621075158641464912"}}},"source":["# encoading the words\n","\n","X_all_int = []\n","for text in X_all_pro:\n","    r = [vocab_to_int[w] for w in text.split()]\n","    X_all_int.append(r)\n","    \n","print (X_all_int[0:3])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[[112, 2, 572, 9, 952, 10, 161, 256, 35, 13, 27, 169, 6, 540, 8, 27, 11, 15, 169, 14, 3, 150, 35], [8, 1, 7, 414, 10, 3, 772, 192], [8, 1, 7, 326, 50, 33, 189, 177, 9, 347, 114, 63, 7, 3, 4683, 1363, 9, 12, 41, 7, 326, 18, 1462, 4684, 6, 283, 550, 43, 606, 4685, 4, 314, 12, 2282]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gPw-Hh7F-fqA","colab_type":"code","colab":{}},"source":["# for convering labels from classes to class index\n","def label_to_int(label_text):\n","    emotions_dict = {\"joy\":0, \"fear\":1, \"anger\":2, \"sadness\":3, \"disgust\":4, \"shame\":5, \"guilt\":6}\n","    label_int = []\n","    for label in label_text:\n","        label_int.append(emotions_dict[label])\n","    return label_int"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vAyyWsfd_UVI","colab_type":"code","colab":{}},"source":["labels = label_to_int(y_all)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ASYEsJaV-vVo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":420},"outputId":"bbc4ad5c-f558-489b-d825-17c5d7269d35","executionInfo":{"status":"ok","timestamp":1558437608797,"user_tz":-330,"elapsed":4489,"user":{"displayName":"GAGAN SINGH SAINI","photoUrl":"","userId":"08621075158641464912"}}},"source":["# analysing the text data lenghth\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","text_len = [len(x) for x in X_all_int]\n","pd.Series(text_len).hist()\n","plt.show()\n","pd.Series(text_len).describe()"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["count    7480.000000\n","mean       22.160160\n","std        14.654072\n","min         1.000000\n","25%        12.000000\n","50%        19.000000\n","75%        30.000000\n","max       178.000000\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"huGUlqzg-xTg","colab_type":"code","colab":{}},"source":["# padding the data for having same dimention\n","import numpy as np\n","\n","def pad_features(text_int, seq_length):\n","    ''' Return features of text_ints, where each text is padded with 0's or truncated to the input seq_length.\n","    '''\n","    features = np.zeros((len(text_int), seq_length), dtype = int)\n","    \n","    for i, text in enumerate(text_int):\n","        text_len = len(text)\n","        \n","        if text_len <= seq_length:\n","            zeroes = list(np.zeros(seq_length-text_len))\n","            new = zeroes+text\n","        elif text_len > seq_length:\n","            new = text[0:seq_length]\n","        \n","        features[i,:] = np.array(new)\n","    \n","    return features"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RONdLDac_eSi","colab_type":"code","colab":{}},"source":["seq_length = 50 # length after padding \n","X_all_pad = pad_features(X_all_int, seq_length)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4jjYkm0A-2IQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"outputId":"dffc723f-a373-4ef1-d856-cabc4771f00d","executionInfo":{"status":"ok","timestamp":1558437659768,"user_tz":-330,"elapsed":1253,"user":{"displayName":"GAGAN SINGH SAINI","photoUrl":"","userId":"08621075158641464912"}}},"source":["print('length of X_all_pad: {}'.format(len(X_all_pad)))\n","print('length of labels: {}'.format(len(labels)))\n","\n","# converting labels from list to numpy.nparray\n","\n","print('data type of labels before convesion: {}'.format(type(labels)))\n","labels = np.array(labels)\n","print('data type of labels after convesion: {}'.format(type(labels)))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["length of X_all_pad: 7480\n","length of labels: 7480\n","data type of labels before convesion: <class 'list'>\n","data type of labels after convesion: <class 'numpy.ndarray'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bGXPZVRg_q4v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":101},"outputId":"e1829314-53e5-495c-df4f-e2f2ef0fe86e","executionInfo":{"status":"ok","timestamp":1558437662224,"user_tz":-330,"elapsed":1326,"user":{"displayName":"GAGAN SINGH SAINI","photoUrl":"","userId":"08621075158641464912"}}},"source":["# train (80%), validation (10%) ,test data (10%) split\n","\n","len_X_all = len(X_all_pad)\n","\n","\n","split_frac = 0.8\n","\n","train_x = X_all_pad[0:int(split_frac*len_X_all)+16]\n","train_y = labels[0:int(split_frac*len_X_all)+16]\n","\n","remaining_x = X_all_pad[int(split_frac*len_X_all)-4:]\n","remaining_y = labels[int(split_frac*len_X_all)-4:]\n","\n","valid_x = remaining_x[0:int(len(remaining_x)*0.5)]\n","valid_y = remaining_y[0:int(len(remaining_y)*0.5)]\n","\n","test_x = remaining_x[int(len(remaining_x)*0.5):]\n","test_y = remaining_y[int(len(remaining_y)*0.5):]\n","\n","print(type(train_x),type(np.array(train_y)))\n","\n","print(\"train data size: \",train_x.shape)\n","print(\"remaining data size: \",remaining_x.shape)\n","print(\"valid data size: \",valid_x.shape)\n","print(\"test data size: \",test_x.shape)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n","train data size:  (6000, 50)\n","remaining data size:  (1500, 50)\n","valid data size:  (750, 50)\n","test data size:  (750, 50)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZM2nCxYp_yMQ","colab_type":"code","colab":{}},"source":["# Data loading and batch formation\n","\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# create Tensor datasets\n","train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n","valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n","test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n","\n","# dataloaders\n","batch_size = 50\n","\n","# Shuffeling the data\n","train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n","test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U7qm2HZ9_4eq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"dc361827-08d8-41fe-ee1c-2fe1b0accc74","executionInfo":{"status":"ok","timestamp":1558437676153,"user_tz":-330,"elapsed":1212,"user":{"displayName":"GAGAN SINGH SAINI","photoUrl":"","userId":"08621075158641464912"}}},"source":["# obtain one batch of training data\n","\n","dataiter = iter(train_loader)\n","sample_x, sample_y = dataiter.next()\n","print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n","print('Sample input: \\n', sample_x)\n","print()\n","print('Sample label size: ', sample_y.size()) # batch_size\n","print('Sample label: \\n', sample_y)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Sample input size:  torch.Size([50, 50])\n","Sample input: \n"," tensor([[   0,    0,    0,  ...,   34, 1411,  804],\n","        [   0,    0,    1,  ...,  724,    5,  697],\n","        [   0,    0,    0,  ...,   55,   16, 6198],\n","        ...,\n","        [   0,    0,    0,  ...,   55,  199,  138],\n","        [   0,    0,    0,  ...,   18,   92, 2756],\n","        [   0,    0,    0,  ...,  315,   30,   17]])\n","\n","Sample label size:  torch.Size([50])\n","Sample label: \n"," tensor([1, 6, 6, 0, 0, 5, 2, 1, 0, 1, 1, 0, 2, 3, 0, 6, 6, 2, 2, 2, 6, 5, 3, 4,\n","        5, 6, 5, 5, 1, 1, 3, 3, 6, 4, 3, 6, 3, 1, 0, 6, 5, 6, 3, 2, 3, 3, 0, 5,\n","        4, 3])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rx9OVCcn__88","colab_type":"code","colab":{}},"source":["# building the model\n","\n","import torch.nn as nn\n","\n","class SentimentLSTM(nn.Module):\n","    \"\"\"\n","    The RNN model that will be used to perform Sentiment analysis.\n","    \"\"\"\n","\n","    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n","        \"\"\"\n","        Initialize the model by setting up the layers.\n","        \"\"\"\n","        super().__init__()\n","\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.hidden_dim = hidden_dim\n","        \n","        # embedding and LSTM layers\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n","        \n","        # dropout layer\n","        self.dropout = nn.Dropout(0.3)\n","        \n","        # linear and Relu layers\n","        self.fc = nn.Linear(hidden_dim, output_size)\n","        self.relu = nn.ReLU()\n","        \n","\n","    def forward(self, x, hidden):\n","        \"\"\"\n","        Perform a forward pass of our model on some input and hidden state.\n","        \"\"\"\n","        batch_size = x.size(0)\n","        seq_len = x.size(1)\n","\n","        # embeddings and lstm_out\n","        embeds = self.embedding(x)\n","        lstm_out, hidden = self.lstm(embeds, hidden)\n","    \n","         # get of labels from last node\n","        lstm_out = lstm_out[:, -1, :]\n","        \n","        # dropout and fully-connected layer\n","        out = self.dropout(lstm_out)\n","        out = self.fc(out)\n","        \n","        # Relu function\n","        relu_out = self.relu(out)\n","        \n","        # return last Relu output and hidden state\n","        return relu_out, hidden\n","    \n","    \n","    # To initialize the hidden state\n","    \n","    def init_hidden(self, batch_size):\n","        ''' Initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        weight = next(self.parameters()).data\n","        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","        if (train_on_gpu):\n","            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n","        else:\n","            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n","        \n","        return hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8GcJDT26A9u1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":151},"outputId":"f1549c84-8113-4247-8f00-439cac610fec","executionInfo":{"status":"ok","timestamp":1558437681273,"user_tz":-330,"elapsed":1464,"user":{"displayName":"GAGAN SINGH SAINI","photoUrl":"","userId":"08621075158641464912"}}},"source":["# Initiating the hyperparams\n","\n","vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n","output_size = 7\n","embedding_dim = 400\n","hidden_dim = 256\n","n_layers = 2\n","\n","# device to train on \n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","# Initiating model and model weights\n","\n","net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n","print(net)\n"],"execution_count":23,"outputs":[{"output_type":"stream","text":["cuda:0\n","SentimentLSTM(\n","  (embedding): Embedding(9340, 400)\n","  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n","  (dropout): Dropout(p=0.3)\n","  (fc): Linear(in_features=256, out_features=7, bias=True)\n","  (relu): ReLU()\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xGQrQWSDBos_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":420},"outputId":"e9b6e87d-9a7e-4091-f5e4-9a2b8ed10111","executionInfo":{"status":"ok","timestamp":1558439883489,"user_tz":-330,"elapsed":18983,"user":{"displayName":"GAGAN SINGH SAINI","photoUrl":"","userId":"08621075158641464912"}}},"source":["# Traing the model\n","\n","lr=0.001 # learning rate\n","\n","# Initiating optimizer\n","\n","import torch.optim as optim\n","optimizer = optim.Adam(net.parameters(),lr=lr)\n","\n","# definig loss function\n","\n","criterion = nn.CrossEntropyLoss()\n","criterion = criterion.to(device)\n","\n","# training params\n","\n","epochs = 10\n","counter = 0\n","print_every = 100\n","clip=5 # gradient clipping to prevent from gradients exploading \n","\n","train_on_gpu = True if torch.cuda.is_available() else False\n","loss = 0\n","\n","# move model to GPU, if available\n","if(train_on_gpu):\n","    net.cuda()\n","\n","# train for some number of epochs\n","\n","net.train()\n","for e in range(epochs):\n","  \n","    # initialize hidden state\n","    h = net.init_hidden(50)\n","    \n","    # for calculating train accuracy every epoch\n","    total = 0\n","    correct = 0\n","    \n","    # batch loop\n","    for inputs, labels in train_loader:\n","        counter += 1\n","\n","        if(train_on_gpu):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # converting cell and hidden state to tuple for feeding into LSTM layer\n","        h = tuple([each.data for each in h])\n","\n","        # Converting accumulated gradients to zero at starting of every epoch\n","        net.zero_grad()\n","      \n","      \n","        # get the output from the model\n","        inputs = inputs.type(torch.LongTensor)\n","        output, h = net(inputs.to(device), h)\n","        \n","        # getting the index of output tensors with max values\n","        _, predicted = torch.max(output.data, 1)\n","    \n","        # for calculating accuracy\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item() # comparing predictions to true label\n","        \n","        \n","        # calculate the loss and perform backprop\n","        loss = criterion(output, labels)\n","        loss.backward()\n","        \n","        # clip_grad_norm helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        nn.utils.clip_grad_norm_(net.parameters(), clip)\n","        optimizer.step()\n","\n","        # loss stats\n","        if counter % print_every == 0:\n","          \n","            # initialize hidden state for validation set\n","            val_h = net.init_hidden(50)\n","            \n","            total_val = 0\n","            correct_val = 0\n","            \n","            val_losses = [] # for tracking loss\n","            net.eval()\n","            for inputs, labels in valid_loader:\n","\n","                # converting cell and hidden state to tuple for feeding into LSTM layer\n","                val_h = tuple([each.data for each in val_h])\n","\n","                if(train_on_gpu):\n","                    inputs, labels = inputs.to(device), labels.to(device)\n","\n","                inputs = inputs.type(torch.LongTensor)\n","                output, val_h = net(inputs.to(device),val_h)\n","                \n","                # getting the index of output tensors with max values\n","                _, predicted_val = torch.max(output.data, 1)\n","    \n","                # for calculating accuracy\n","                total_val += labels.size(0)\n","                correct_val += (predicted_val == labels).sum().item() # comparing predictions to true label\n","\n","                val_loss = criterion(output, labels)\n","\n","                val_losses.append(val_loss.item())\n","\n","            net.train()\n","            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n","                  \"Step: {}...\".format(counter),\n","                  \"Loss: {:.6f}...\".format(loss.item()),\n","                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n","            \n","            print(\"Train accuracy: {}\".format((correct / total) * 100),\n","                  \"Val accuracy: {}\".format((correct_val / total_val) * 100))"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Epoch: 1/10... Step: 100... Loss: 0.039047... Val Loss: 3.581677\n","Train accuracy: 99.66000000000001 Val accuracy: 57.46666666666667\n","Epoch: 2/10... Step: 200... Loss: 0.000012... Val Loss: 3.683197\n","Train accuracy: 99.7 Val accuracy: 57.86666666666667\n","Epoch: 3/10... Step: 300... Loss: 0.001063... Val Loss: 3.745631\n","Train accuracy: 99.76666666666667 Val accuracy: 56.8\n","Epoch: 4/10... Step: 400... Loss: 0.000182... Val Loss: 3.776997\n","Train accuracy: 99.75 Val accuracy: 56.53333333333334\n","Epoch: 5/10... Step: 500... Loss: 0.000017... Val Loss: 3.735685\n","Train accuracy: 99.7 Val accuracy: 56.39999999999999\n","Epoch: 5/10... Step: 600... Loss: 0.034949... Val Loss: 3.791756\n","Train accuracy: 99.63333333333333 Val accuracy: 56.53333333333334\n","Epoch: 6/10... Step: 700... Loss: 0.000007... Val Loss: 3.744663\n","Train accuracy: 99.56 Val accuracy: 57.733333333333334\n","Epoch: 7/10... Step: 800... Loss: 0.112086... Val Loss: 3.843065\n","Train accuracy: 99.675 Val accuracy: 56.53333333333334\n","Epoch: 8/10... Step: 900... Loss: 0.035150... Val Loss: 3.751937\n","Train accuracy: 99.63333333333333 Val accuracy: 56.666666666666664\n","Epoch: 9/10... Step: 1000... Loss: 0.001817... Val Loss: 3.662816\n","Train accuracy: 99.65 Val accuracy: 57.733333333333334\n","Epoch: 10/10... Step: 1100... Loss: 0.000218... Val Loss: 3.771669\n","Train accuracy: 99.5 Val accuracy: 57.46666666666667\n","Epoch: 10/10... Step: 1200... Loss: 0.000026... Val Loss: 3.869749\n","Train accuracy: 99.63333333333333 Val accuracy: 55.60000000000001\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0Dz1kk58EVOt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"8be9cb94-b3aa-4725-d070-3813ebdd52fa","executionInfo":{"status":"ok","timestamp":1558439890660,"user_tz":-330,"elapsed":1447,"user":{"displayName":"GAGAN SINGH SAINI","photoUrl":"","userId":"08621075158641464912"}}},"source":["test_losses = [] # for tracking loss\n","\n","\n","# init hidden state\n","h = net.init_hidden(batch_size)\n","total = 0\n","correct = 0\n","net.eval()\n","\n","# iterate over test data\n","for inputs, labels in test_loader:\n","\n","    h = tuple([each.data for each in h])\n","\n","    if(train_on_gpu):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","    # get predicted outputs\n","    inputs = inputs.type(torch.LongTensor)\n","    output, h = net(inputs.to(device), h)\n","    \n","    # getting the index of output tensors with max values\n","    _, predicted = torch.max(output.data, 1)\n","    \n","    # for calculating accuracy\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum().item() # comparing predictions to true label\n","\n","    \n","    test_loss = criterion(output, labels)\n","    test_losses.append(test_loss.item())\n","    \n","print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))    \n","print('Accuracy of the network on the test data : {} %'.format((correct / total) * 100))"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Test loss: 4.582\n","Accuracy of the network on the test data : 46.93333333333333 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Cvuz7fikF4qb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"outputId":"289cdecc-d59e-4086-a09e-de04fd6d65e1","executionInfo":{"status":"ok","timestamp":1558439898616,"user_tz":-330,"elapsed":1174,"user":{"displayName":"GAGAN SINGH SAINI","photoUrl":"","userId":"08621075158641464912"}}},"source":["# testing on custom dataset\n","\n","from string import punctuation\n","\n","# for tranforming the string into tokens\n","\n","def tokenize_text(test_text):\n","    test_text = test_text.lower() # lowercase\n","    \n","    # get rid of punctuation\n","    test_text = ''.join([c for c in test_text if c not in punctuation])\n","\n","    # splitting the lines into words for tokenization\n","    test_words = test_text.split()\n","\n","    # tokenizing the text\n","    test_ints = []\n","    test_ints.append([vocab_to_int[word] for word in test_words])\n","\n","    return test_ints\n","  \n","# test string\n","test_text = \"I am very angry and sad !! :)\"\n","\n","\n","def predict(net, test_text, sequence_length=50):\n","    \n","    net.eval()\n","    \n","    # tokenize text\n","    test_ints = tokenize_text(test_text)\n","    \n","    # pad tokenized sequence\n","    seq_length=sequence_length\n","    features = pad_features(test_ints, seq_length)\n","    \n","    # convering the array to tensor to pass into the model\n","    feature_tensor = torch.from_numpy(features)\n","    \n","    batch_size = feature_tensor.size(0) # number of strings to test\n","\n","    # initialize hidden state\n","    h = net.init_hidden(batch_size)\n","    \n","    if(train_on_gpu):\n","        feature_tensor = feature_tensor.to(device)\n","    \n","    # get the output from the model\n","    output, h = net(feature_tensor, h)\n","    print(output.cpu().detach().numpy())\n","    print(emotions)\n","\n","    _, predicted = torch.max(output.data, 1)\n","    print(\"{} --> {}\".format(test_text, emotions[predicted.cpu().numpy()[0]]))\n","\n","    \n","predict(net, test_text, sequence_length=50)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["[[ 0.          0.          0.74669385 12.964067    0.          0.\n","   0.        ]]\n","['joy', 'fear', 'anger', 'sadness', 'disgust', 'shame', 'guilt']\n","I am very angry and sad !! :) --> sadness\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VpIBhGb5Lvm5","colab_type":"code","colab":{}},"source":["torch.save(net.state_dict(), 'model_sentiment analysis_v1.pt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WoTnGT2oOdEz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}