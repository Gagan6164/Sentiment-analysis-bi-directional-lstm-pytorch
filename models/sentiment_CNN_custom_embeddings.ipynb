{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_CNN_custom_embeddings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d991--97s6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1.) function for reading data and formatting\n",
        "\n",
        "def read_file(file_name): \n",
        "    data_list  = []\n",
        "    with open(file_name, 'r') as f: \n",
        "        for line in f: \n",
        "            line = line.strip() \n",
        "            label = ' '.join(line[1:line.find(\"]\")].strip().split())\n",
        "            text = line[line.find(\"]\")+1:].strip()\n",
        "            data_list.append([label, text])\n",
        "    return data_list "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX5nWNFt8Tv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# file path\n",
        "\n",
        "file_name = \"../content/psychExp.txt\"\n",
        "psychExp_txt = read_file(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrq5jLiB9b1x",
        "colab_type": "code",
        "outputId": "3272d6b5-693a-4db6-f348-267b64cc7875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Total no. of instances: {}'.format(len(psychExp_txt)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of instances: 7480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbzMka0m9iMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# method for converting labels from one hot to classes\n",
        "\n",
        "def convert_label(item, name): \n",
        "    items = list(map(float, item.split()))\n",
        "    label = \"\"\n",
        "    for idx in range(len(items)): \n",
        "        if items[idx] == 1: \n",
        "            label += name[idx] + \" \"\n",
        "    \n",
        "    return label.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqWMWTPg9yUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classes\n",
        "\n",
        "emotions = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGNK_nnJ92kL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_all = []\n",
        "y_all = []\n",
        "for label, text in psychExp_txt:\n",
        "    X_all.append(text.lower())\n",
        "    y_all.append(convert_label(label, emotions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRcy55bR-HEj",
        "colab_type": "code",
        "outputId": "c9dd0d36-9297-4660-c377-5545bc91c43b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Data processing\n",
        "\n",
        "from string import punctuation\n",
        "print('punctuations to be removed: {}'.format(punctuation))\n",
        "\n",
        "X_all_pro = []\n",
        "for text in X_all:\n",
        "    all_text = ''.join([c for c in text if c not in punctuation])\n",
        "    X_all_pro.append(all_text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "punctuations to be removed: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKpeKerW-IIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize — Create Vocab to Int mapping dictionary\n",
        "\n",
        "from collections import Counter\n",
        "all_text2 = ' '.join(X_all_pro)\n",
        "\n",
        "# create a list of words\n",
        "words = all_text2.split()\n",
        "\n",
        "# Count all the words using Counter Method\n",
        "count_words = Counter(words)\n",
        "\n",
        "total_words = len(words)\n",
        "sorted_words = count_words.most_common(total_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tb8dmHnsLw1",
        "colab_type": "code",
        "outputId": "fd8dd2c0-28c5-4d6c-c415-bf2eca52cca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "sorted_words.insert(0,('',11000))\n",
        "print(len(sorted_words))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUTahaws-QxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vocab to integer mapping dictionary with starting index 1\n",
        "\n",
        "vocab_to_int = {w:i for i, (w,c) in enumerate(sorted_words)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idoHTIO-tvGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_vocab = []\n",
        "for i, (w,c) in enumerate(sorted_words):\n",
        "  target_vocab.append(w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVnXDeP7-Uni",
        "colab_type": "code",
        "outputId": "5a66333b-7bec-43a5-a9f0-eda6f5f7ea07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# encoading the words\n",
        "\n",
        "X_all_int = []\n",
        "for text in X_all_pro:\n",
        "    r = [vocab_to_int[w] for w in text.split()]\n",
        "    X_all_int.append(r)\n",
        "    \n",
        "print (X_all_int[0:3])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[112, 2, 572, 9, 952, 10, 161, 256, 35, 13, 27, 169, 6, 540, 8, 27, 11, 15, 169, 14, 3, 150, 35], [8, 1, 7, 414, 10, 3, 772, 192], [8, 1, 7, 326, 50, 33, 189, 177, 9, 347, 114, 63, 7, 3, 4683, 1363, 9, 12, 41, 7, 326, 18, 1462, 4684, 6, 283, 550, 43, 606, 4685, 4, 314, 12, 2282]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPw-Hh7F-fqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for convering labels from classes to class index\n",
        "def label_to_int(label_text):\n",
        "    emotions_dict = {\"joy\":0, \"fear\":1, \"anger\":2, \"sadness\":3, \"disgust\":4, \"shame\":5, \"guilt\":6}\n",
        "    label_int = []\n",
        "    for label in label_text:\n",
        "        label_int.append(emotions_dict[label])\n",
        "    return label_int\n",
        "  \n",
        "  \n",
        "labels = label_to_int(y_all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASYEsJaV-vVo",
        "colab_type": "code",
        "outputId": "e27c5251-0df4-4cb7-dd7f-1073c0e5a2be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "# analysing the text data lenghth\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "text_len = [len(x) for x in X_all_int]\n",
        "pd.Series(text_len).hist()\n",
        "plt.show()\n",
        "pd.Series(text_len).describe()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    7480.000000\n",
              "mean       22.160160\n",
              "std        14.654072\n",
              "min         1.000000\n",
              "25%        12.000000\n",
              "50%        19.000000\n",
              "75%        30.000000\n",
              "max       178.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huGUlqzg-xTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# padding the data for having same dimention\n",
        "import numpy as np\n",
        "\n",
        "def pad_features(text_int, seq_length):\n",
        "    ''' Return features of text_ints, where each text is padded with 0's or truncated to the input seq_length.\n",
        "    '''\n",
        "    features = np.zeros((len(text_int), seq_length), dtype = int)\n",
        "    \n",
        "    for i, text in enumerate(text_int):\n",
        "        text_len = len(text)\n",
        "        \n",
        "        if text_len <= seq_length:\n",
        "            zeroes = list(np.zeros(seq_length-text_len))\n",
        "            new = zeroes+text\n",
        "        elif text_len > seq_length:\n",
        "            new = text[0:seq_length]\n",
        "        \n",
        "        features[i,:] = np.array(new)\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RONdLDac_eSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = 64 # length after padding \n",
        "X_all_pad = pad_features(X_all_int, seq_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jjYkm0A-2IQ",
        "colab_type": "code",
        "outputId": "00dde15e-e747-4644-895f-76df497c2107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print('length of X_all_pad: {}'.format(len(X_all_pad)))\n",
        "print('length of labels: {}'.format(len(labels)))\n",
        "\n",
        "# converting labels from list to numpy.nparray\n",
        "\n",
        "print('data type of labels before convesion: {}'.format(type(labels)))\n",
        "labels = np.array(labels)\n",
        "print('data type of labels after convesion: {}'.format(type(labels)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of X_all_pad: 7480\n",
            "length of labels: 7480\n",
            "data type of labels before convesion: <class 'list'>\n",
            "data type of labels after convesion: <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGXPZVRg_q4v",
        "colab_type": "code",
        "outputId": "2006d47e-bf11-4afc-bf9e-83bd68bcc7ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# train (80%), validation (10%) ,test data (10%) split\n",
        "\n",
        "len_X_all = len(X_all_pad)\n",
        "\n",
        "\n",
        "split_frac = 0.8\n",
        "\n",
        "train_x = X_all_pad[0:int(split_frac*len_X_all)+16]\n",
        "train_y = labels[0:int(split_frac*len_X_all)+16]\n",
        "\n",
        "remaining_x = X_all_pad[int(split_frac*len_X_all)-4:]\n",
        "remaining_y = labels[int(split_frac*len_X_all)-4:]\n",
        "\n",
        "test_x = remaining_x[0:int(len(remaining_x)*0.5)]\n",
        "test_y = remaining_y[0:int(len(remaining_y)*0.5)]\n",
        "\n",
        "valid_x = remaining_x[int(len(remaining_x)*0.5):]\n",
        "valid_y = remaining_y[int(len(remaining_y)*0.5):]\n",
        "\n",
        "print(type(train_x),type(np.array(train_y)))\n",
        "\n",
        "print(\"train data size: \",train_x.shape)\n",
        "print(\"remaining data size: \",remaining_x.shape)\n",
        "print(\"valid data size: \",valid_x.shape)\n",
        "print(\"test data size: \",test_x.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "train data size:  (6000, 64)\n",
            "remaining data size:  (1500, 64)\n",
            "valid data size:  (750, 64)\n",
            "test data size:  (750, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM2nCxYp_yMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data loading and batch formation\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "# Shuffeling the data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7qm2HZ9_4eq",
        "colab_type": "code",
        "outputId": "eace0298-19d7-4ba2-d28b-f1072ae0b588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# obtain one batch of training data\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([50, 64])\n",
            "Sample input: \n",
            " tensor([[   0,    0,    0,  ...,   57, 3952,  515],\n",
            "        [   0,    0,    0,  ...,   59,    5,  246],\n",
            "        [   0,    0,    0,  ..., 1453,    5,  972],\n",
            "        ...,\n",
            "        [   0,    0,    0,  ...,    1,   22,  121],\n",
            "        [   0,    0,    0,  ..., 3773,   32,   60],\n",
            "        [   0,    0,    0,  ...,  108,  134,   12]])\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([6, 6, 6, 6, 0, 6, 4, 6, 0, 6, 4, 6, 0, 0, 0, 2, 3, 5, 5, 0, 1, 4, 3, 4,\n",
            "        1, 5, 1, 0, 0, 4, 2, 3, 0, 3, 5, 4, 0, 4, 1, 6, 6, 1, 1, 6, 2, 3, 2, 5,\n",
            "        1, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4IeybPBsUh-",
        "colab_type": "text"
      },
      "source": [
        "# Building the model #\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx9OVCcn__88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# building the model\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SentimentCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,vocab_size, output_size, embedding_dim, num_filters, window_sizes, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.num_filters = num_filters\n",
        "        \n",
        "        self.window_sizes = window_sizes\n",
        "        \n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(1, num_filters, [window_size, embedding_dim], padding=(window_size - 1, 0))\n",
        "            for window_size in window_sizes\n",
        "        ])\n",
        "        \n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        \n",
        "        self.fc = nn.Linear(num_filters * len(window_sizes), output_size)\n",
        "        \n",
        "        self.softmax = nn.Softmax()\n",
        "        \n",
        "\n",
        "    def forward(self, x ):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "\n",
        "        # embeddings and cnn\n",
        "        x = self.embedding(x)\n",
        "        x = torch.unsqueeze(x, 1)       # [B, C, T, E] Add a channel dim.\n",
        "        xs = []\n",
        "        for conv in self.convs:\n",
        "            x2 = F.relu(conv(x))        # [B, F, T, 1]\n",
        "            x2 = torch.squeeze(x2, -1)  # [B, F, T]\n",
        "            x2 = F.max_pool1d(x2, x2.size(2))  # [B, F, 1]\n",
        "            xs.append(x2)\n",
        "        x = torch.cat(xs, 2)            # [B, F, window]\n",
        "\n",
        "        # FC\n",
        "        x = x.view(x.size(0), -1)       # [B, F * window]\n",
        "        logits = self.fc(x)             # [B, class]\n",
        "\n",
        "        # Prediction\n",
        "        probs = F.softmax(logits)       # [B, class]\n",
        "\n",
        "        return probs \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkgDxMxisPkA",
        "colab_type": "text"
      },
      "source": [
        "## Initializing the model ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GcJDT26A9u1",
        "colab_type": "code",
        "outputId": "d3309242-44ad-4ff8-ec78-116f8bd3ab86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# Initiating the hyperparams\n",
        "\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
        "output_size = 7\n",
        "embedding_dim = 400\n",
        "num_filters = 128\n",
        "window_sizes= (3, 4, 5)\n",
        "\n",
        "\n",
        "\n",
        "# device to train on \n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# Initiating model and model weights\n",
        "\n",
        "net = SentimentCNN(vocab_size, output_size, embedding_dim, num_filters, window_sizes)\n",
        "net.to(device)\n",
        "print(net)\n",
        "\n",
        "def weight_reset(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear) or isinstance(m, nn.Embedding):\n",
        "        m.reset_parameters()\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "SentimentCNN(\n",
            "  (embedding): Embedding(9341, 400)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv2d(1, 128, kernel_size=[3, 400], stride=(1, 1), padding=(2, 0))\n",
            "    (1): Conv2d(1, 128, kernel_size=[4, 400], stride=(1, 1), padding=(3, 0))\n",
            "    (2): Conv2d(1, 128, kernel_size=[5, 400], stride=(1, 1), padding=(4, 0))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.3)\n",
            "  (fc): Linear(in_features=384, out_features=7, bias=True)\n",
            "  (softmax): Softmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU19-LBic08o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_hparam_string(learning_rate):\n",
        "  return \"lr_%.0E\" % (learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM8dYD1esKhn",
        "colab_type": "text"
      },
      "source": [
        "# Training the model #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGQrQWSDBos_",
        "colab_type": "code",
        "outputId": "c0ce23f6-6826-41cb-b037-40be510d8783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57543
        }
      },
      "source": [
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "# Traing the model\n",
        "\n",
        "since = time.time()\n",
        "\n",
        "best_model_wts = copy.deepcopy(net.state_dict())\n",
        "best_acc = 0.0 # tensorboard helper module to visualize accuracy and loss\n",
        "clip=5 # gradient clipping to prevent from gradients exploading\n",
        "\n",
        "from logger import Logger\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "lrs=[0.0001,0.0005,0.001,0.002,0.005,0.01] # learning rate\n",
        "\n",
        "# Initiating optimizer\n",
        "\n",
        "for lr in lrs:\n",
        "    net.apply(weight_reset)\n",
        "    hparam = make_hparam_string(lr)\n",
        "    \n",
        "\n",
        "    logger = Logger('../content/logs/'+hparam)\n",
        "    #optimizer = optim.Adam(net.parameters(),lr=lr)\n",
        "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    # definig loss function\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    # training params\n",
        "\n",
        "    epochs = 100\n",
        "    counter = 0\n",
        "    print_every = 130\n",
        "\n",
        "    train_on_gpu = True if torch.cuda.is_available() else False\n",
        "    loss = 0\n",
        "\n",
        "    # move model to GPU, if available\n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "\n",
        "    # train for some number of epochs\n",
        "\n",
        "\n",
        "    for e in range(epochs):\n",
        "\n",
        "        \n",
        "\n",
        "        # for calculating train accuracy every epoch\n",
        "        total = 0\n",
        "        correct = 0\n",
        "\n",
        "        net.train()\n",
        "\n",
        "        # batch loop\n",
        "        for inputs, labels in train_loader:\n",
        "            counter += 1\n",
        "\n",
        "            if(train_on_gpu):\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "            # Converting accumulated gradients to zero at starting of every epoch\n",
        "            net.zero_grad()\n",
        "\n",
        "\n",
        "            # get the output from the model\n",
        "            inputs = inputs.type(torch.LongTensor)\n",
        "            output = net(inputs.to(device))\n",
        "\n",
        "            # getting the index of output tensors with max values\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "            # for calculating accuracy\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item() # comparing predictions to true label\n",
        "\n",
        "\n",
        "            # calculate the loss and perform backprop\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            \n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            _, argmax = torch.max(output, 1)\n",
        "            accuracy = (labels == argmax.squeeze()).float().mean()\n",
        "\n",
        "            # loss stats\n",
        "            if counter % print_every == 0:\n",
        "\n",
        "\n",
        "\n",
        "                info = { 'loss': loss.item(), 'accuracy': accuracy.item() }\n",
        "\n",
        "                for tag, value in info.items():\n",
        "                    logger.scalar_summary(tag, value, counter+1)\n",
        "\n",
        "                    # 2. Log values and gradients of the parameters (histogram summary)\n",
        "                for tag, value in net.named_parameters():\n",
        "                    tag = tag.replace('.', '/')\n",
        "                    logger.histo_summary(tag, value.data.cpu().numpy(), counter+1)\n",
        "                    if value.grad is not None:\n",
        "                        logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), counter+1)\n",
        "\n",
        "                \n",
        "\n",
        "                total_val = 0\n",
        "                correct_val = 0\n",
        "\n",
        "                val_losses = [] # for tracking loss\n",
        "                net.eval()\n",
        "                for inputs, labels in valid_loader:\n",
        "\n",
        "                    if(train_on_gpu):\n",
        "                        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                    inputs = inputs.type(torch.LongTensor)\n",
        "                    output = net(inputs.to(device))\n",
        "\n",
        "                    # getting the index of output tensors with max values\n",
        "                    _, predicted_val = torch.max(output.data, 1)\n",
        "\n",
        "                    # for calculating accuracy\n",
        "                    total_val += labels.size(0)\n",
        "                    correct_val += (predicted_val == labels).sum().item() # comparing predictions to true label\n",
        "\n",
        "                    val_loss = criterion(output, labels)\n",
        "\n",
        "                    val_losses.append(val_loss.item())\n",
        "\n",
        "                net.train()\n",
        "\n",
        "                val_acc = (correct_val / total_val) * 100\n",
        "\n",
        "                # deep copy the model\n",
        "                if (val_acc > best_acc):\n",
        "                    best_acc = val_acc\n",
        "                    print(\"saving model .....\")\n",
        "                    best_model_wts = copy.deepcopy(net.state_dict())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                print(\"-\"*10)\n",
        "                print(\"\")\n",
        "                print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
        "                      \"Step: {}\".format(counter),\n",
        "                      \"Loss: {:.4f}\".format(loss.item()),\n",
        "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
        "\n",
        "\n",
        "                print(\"Train accuracy: {:.2f}\".format((correct / total) * 100), \"Val accuracy: {:.2f}\".format(val_acc))\n",
        "                print(\"\")\n",
        "                print(\"-\"*10)\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 2/100 Step: 130 Loss: 1.9424 Val Loss: 1.9488\n",
            "Train accuracy: 15.00 Val accuracy: 12.13\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 3/100 Step: 260 Loss: 1.9527 Val Loss: 1.9479\n",
            "Train accuracy: 13.20 Val accuracy: 13.07\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 4/100 Step: 390 Loss: 1.9489 Val Loss: 1.9472\n",
            "Train accuracy: 15.07 Val accuracy: 14.27\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 5/100 Step: 520 Loss: 1.9446 Val Loss: 1.9466\n",
            "Train accuracy: 16.60 Val accuracy: 15.47\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 6/100 Step: 650 Loss: 1.9394 Val Loss: 1.9461\n",
            "Train accuracy: 16.88 Val accuracy: 16.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 7/100 Step: 780 Loss: 1.9501 Val Loss: 1.9456\n",
            "Train accuracy: 17.53 Val accuracy: 16.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 8/100 Step: 910 Loss: 1.9458 Val Loss: 1.9451\n",
            "Train accuracy: 18.03 Val accuracy: 16.40\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 9/100 Step: 1040 Loss: 1.9348 Val Loss: 1.9446\n",
            "Train accuracy: 18.98 Val accuracy: 17.20\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 10/100 Step: 1170 Loss: 1.9361 Val Loss: 1.9441\n",
            "Train accuracy: 19.40 Val accuracy: 17.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 11/100 Step: 1300 Loss: 1.9337 Val Loss: 1.9436\n",
            "Train accuracy: 19.78 Val accuracy: 16.67\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 12/100 Step: 1430 Loss: 1.9360 Val Loss: 1.9432\n",
            "Train accuracy: 21.05 Val accuracy: 18.40\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 13/100 Step: 1560 Loss: 1.9428 Val Loss: 1.9427\n",
            "Train accuracy: 21.17 Val accuracy: 18.53\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 15/100 Step: 1690 Loss: 1.9271 Val Loss: 1.9422\n",
            "Train accuracy: 24.00 Val accuracy: 18.80\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 16/100 Step: 1820 Loss: 1.9338 Val Loss: 1.9418\n",
            "Train accuracy: 21.80 Val accuracy: 19.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 17/100 Step: 1950 Loss: 1.9348 Val Loss: 1.9414\n",
            "Train accuracy: 23.80 Val accuracy: 18.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 18/100 Step: 2080 Loss: 1.9436 Val Loss: 1.9409\n",
            "Train accuracy: 22.80 Val accuracy: 18.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 19/100 Step: 2210 Loss: 1.9303 Val Loss: 1.9405\n",
            "Train accuracy: 23.48 Val accuracy: 19.07\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 20/100 Step: 2340 Loss: 1.9302 Val Loss: 1.9400\n",
            "Train accuracy: 23.90 Val accuracy: 20.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 21/100 Step: 2470 Loss: 1.9267 Val Loss: 1.9396\n",
            "Train accuracy: 24.31 Val accuracy: 19.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 22/100 Step: 2600 Loss: 1.9278 Val Loss: 1.9391\n",
            "Train accuracy: 24.73 Val accuracy: 19.73\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 23/100 Step: 2730 Loss: 1.9298 Val Loss: 1.9386\n",
            "Train accuracy: 24.62 Val accuracy: 21.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 24/100 Step: 2860 Loss: 1.9359 Val Loss: 1.9382\n",
            "Train accuracy: 24.78 Val accuracy: 20.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 25/100 Step: 2990 Loss: 1.9264 Val Loss: 1.9377\n",
            "Train accuracy: 25.53 Val accuracy: 20.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 26/100 Step: 3120 Loss: 1.9288 Val Loss: 1.9372\n",
            "Train accuracy: 25.30 Val accuracy: 20.93\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 28/100 Step: 3250 Loss: 1.9320 Val Loss: 1.9367\n",
            "Train accuracy: 26.60 Val accuracy: 21.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 29/100 Step: 3380 Loss: 1.9202 Val Loss: 1.9362\n",
            "Train accuracy: 24.60 Val accuracy: 21.47\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 30/100 Step: 3510 Loss: 1.9232 Val Loss: 1.9357\n",
            "Train accuracy: 27.00 Val accuracy: 21.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 31/100 Step: 3640 Loss: 1.9181 Val Loss: 1.9351\n",
            "Train accuracy: 27.15 Val accuracy: 21.73\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 32/100 Step: 3770 Loss: 1.8866 Val Loss: 1.9346\n",
            "Train accuracy: 25.64 Val accuracy: 21.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 33/100 Step: 3900 Loss: 1.9333 Val Loss: 1.9341\n",
            "Train accuracy: 26.87 Val accuracy: 21.87\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 34/100 Step: 4030 Loss: 1.9221 Val Loss: 1.9335\n",
            "Train accuracy: 26.91 Val accuracy: 22.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 35/100 Step: 4160 Loss: 1.9135 Val Loss: 1.9330\n",
            "Train accuracy: 26.52 Val accuracy: 22.00\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 36/100 Step: 4290 Loss: 1.9092 Val Loss: 1.9324\n",
            "Train accuracy: 26.82 Val accuracy: 22.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 37/100 Step: 4420 Loss: 1.9277 Val Loss: 1.9318\n",
            "Train accuracy: 27.24 Val accuracy: 22.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 38/100 Step: 4550 Loss: 1.9209 Val Loss: 1.9313\n",
            "Train accuracy: 27.25 Val accuracy: 22.53\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 39/100 Step: 4680 Loss: 1.9218 Val Loss: 1.9307\n",
            "Train accuracy: 27.07 Val accuracy: 23.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 41/100 Step: 4810 Loss: 1.9089 Val Loss: 1.9301\n",
            "Train accuracy: 22.20 Val accuracy: 22.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 42/100 Step: 4940 Loss: 1.9099 Val Loss: 1.9295\n",
            "Train accuracy: 30.30 Val accuracy: 22.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 43/100 Step: 5070 Loss: 1.9298 Val Loss: 1.9289\n",
            "Train accuracy: 27.47 Val accuracy: 22.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 44/100 Step: 5200 Loss: 1.9276 Val Loss: 1.9283\n",
            "Train accuracy: 27.55 Val accuracy: 22.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 45/100 Step: 5330 Loss: 1.9154 Val Loss: 1.9276\n",
            "Train accuracy: 27.96 Val accuracy: 22.93\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 46/100 Step: 5460 Loss: 1.9050 Val Loss: 1.9269\n",
            "Train accuracy: 27.17 Val accuracy: 23.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 47/100 Step: 5590 Loss: 1.9050 Val Loss: 1.9263\n",
            "Train accuracy: 27.14 Val accuracy: 23.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 48/100 Step: 5720 Loss: 1.8971 Val Loss: 1.9257\n",
            "Train accuracy: 28.38 Val accuracy: 23.47\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 49/100 Step: 5850 Loss: 1.9325 Val Loss: 1.9250\n",
            "Train accuracy: 28.44 Val accuracy: 23.73\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 50/100 Step: 5980 Loss: 1.9211 Val Loss: 1.9243\n",
            "Train accuracy: 28.44 Val accuracy: 24.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 51/100 Step: 6110 Loss: 1.8702 Val Loss: 1.9237\n",
            "Train accuracy: 28.78 Val accuracy: 24.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 52/100 Step: 6240 Loss: 1.8730 Val Loss: 1.9230\n",
            "Train accuracy: 28.67 Val accuracy: 23.87\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 54/100 Step: 6370 Loss: 1.8446 Val Loss: 1.9224\n",
            "Train accuracy: 31.00 Val accuracy: 24.40\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 55/100 Step: 6500 Loss: 1.9149 Val Loss: 1.9216\n",
            "Train accuracy: 29.20 Val accuracy: 24.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 56/100 Step: 6630 Loss: 1.8852 Val Loss: 1.9210\n",
            "Train accuracy: 29.13 Val accuracy: 24.53\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 57/100 Step: 6760 Loss: 1.9110 Val Loss: 1.9203\n",
            "Train accuracy: 30.60 Val accuracy: 24.93\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 58/100 Step: 6890 Loss: 1.8979 Val Loss: 1.9196\n",
            "Train accuracy: 28.60 Val accuracy: 25.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 59/100 Step: 7020 Loss: 1.9187 Val Loss: 1.9189\n",
            "Train accuracy: 29.80 Val accuracy: 25.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 60/100 Step: 7150 Loss: 1.8786 Val Loss: 1.9182\n",
            "Train accuracy: 29.94 Val accuracy: 24.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 61/100 Step: 7280 Loss: 1.8853 Val Loss: 1.9175\n",
            "Train accuracy: 29.53 Val accuracy: 24.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 62/100 Step: 7410 Loss: 1.9032 Val Loss: 1.9167\n",
            "Train accuracy: 29.60 Val accuracy: 25.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 63/100 Step: 7540 Loss: 1.8545 Val Loss: 1.9161\n",
            "Train accuracy: 30.66 Val accuracy: 24.93\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 64/100 Step: 7670 Loss: 1.8970 Val Loss: 1.9153\n",
            "Train accuracy: 31.04 Val accuracy: 25.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 65/100 Step: 7800 Loss: 1.9016 Val Loss: 1.9146\n",
            "Train accuracy: 30.83 Val accuracy: 25.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 67/100 Step: 7930 Loss: 1.8950 Val Loss: 1.9139\n",
            "Train accuracy: 29.80 Val accuracy: 25.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 68/100 Step: 8060 Loss: 1.8906 Val Loss: 1.9131\n",
            "Train accuracy: 31.30 Val accuracy: 25.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 69/100 Step: 8190 Loss: 1.8746 Val Loss: 1.9124\n",
            "Train accuracy: 30.07 Val accuracy: 25.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 70/100 Step: 8320 Loss: 1.8950 Val Loss: 1.9117\n",
            "Train accuracy: 33.10 Val accuracy: 25.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 71/100 Step: 8450 Loss: 1.8462 Val Loss: 1.9109\n",
            "Train accuracy: 32.24 Val accuracy: 25.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 72/100 Step: 8580 Loss: 1.8571 Val Loss: 1.9102\n",
            "Train accuracy: 32.53 Val accuracy: 25.47\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 73/100 Step: 8710 Loss: 1.8400 Val Loss: 1.9095\n",
            "Train accuracy: 32.26 Val accuracy: 25.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 74/100 Step: 8840 Loss: 1.8592 Val Loss: 1.9086\n",
            "Train accuracy: 33.25 Val accuracy: 25.47\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 75/100 Step: 8970 Loss: 1.8863 Val Loss: 1.9079\n",
            "Train accuracy: 33.56 Val accuracy: 25.47\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 76/100 Step: 9100 Loss: 1.8665 Val Loss: 1.9071\n",
            "Train accuracy: 32.94 Val accuracy: 25.73\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 77/100 Step: 9230 Loss: 1.8788 Val Loss: 1.9064\n",
            "Train accuracy: 34.27 Val accuracy: 26.00\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 78/100 Step: 9360 Loss: 1.9128 Val Loss: 1.9056\n",
            "Train accuracy: 34.25 Val accuracy: 26.40\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 80/100 Step: 9490 Loss: 1.9069 Val Loss: 1.9048\n",
            "Train accuracy: 32.80 Val accuracy: 26.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 81/100 Step: 9620 Loss: 1.8744 Val Loss: 1.9041\n",
            "Train accuracy: 36.00 Val accuracy: 26.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 82/100 Step: 9750 Loss: 1.8762 Val Loss: 1.9033\n",
            "Train accuracy: 34.07 Val accuracy: 26.13\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 83/100 Step: 9880 Loss: 1.9070 Val Loss: 1.9025\n",
            "Train accuracy: 35.35 Val accuracy: 26.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 84/100 Step: 10010 Loss: 1.8808 Val Loss: 1.9018\n",
            "Train accuracy: 34.32 Val accuracy: 26.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 85/100 Step: 10140 Loss: 1.8595 Val Loss: 1.9011\n",
            "Train accuracy: 35.07 Val accuracy: 26.93\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 86/100 Step: 10270 Loss: 1.8750 Val Loss: 1.9002\n",
            "Train accuracy: 36.34 Val accuracy: 27.07\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 87/100 Step: 10400 Loss: 1.8876 Val Loss: 1.8994\n",
            "Train accuracy: 35.98 Val accuracy: 27.20\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 88/100 Step: 10530 Loss: 1.9000 Val Loss: 1.8987\n",
            "Train accuracy: 36.02 Val accuracy: 27.47\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 89/100 Step: 10660 Loss: 1.8244 Val Loss: 1.8979\n",
            "Train accuracy: 36.94 Val accuracy: 27.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 90/100 Step: 10790 Loss: 1.8878 Val Loss: 1.8971\n",
            "Train accuracy: 37.20 Val accuracy: 27.20\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 91/100 Step: 10920 Loss: 1.8559 Val Loss: 1.8963\n",
            "Train accuracy: 37.08 Val accuracy: 28.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 93/100 Step: 11050 Loss: 1.8768 Val Loss: 1.8956\n",
            "Train accuracy: 31.20 Val accuracy: 27.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 94/100 Step: 11180 Loss: 1.8650 Val Loss: 1.8949\n",
            "Train accuracy: 38.70 Val accuracy: 27.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 95/100 Step: 11310 Loss: 1.8283 Val Loss: 1.8942\n",
            "Train accuracy: 38.47 Val accuracy: 27.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 96/100 Step: 11440 Loss: 1.8477 Val Loss: 1.8932\n",
            "Train accuracy: 36.40 Val accuracy: 28.13\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 97/100 Step: 11570 Loss: 1.8223 Val Loss: 1.8925\n",
            "Train accuracy: 38.92 Val accuracy: 28.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 98/100 Step: 11700 Loss: 1.8622 Val Loss: 1.8918\n",
            "Train accuracy: 38.10 Val accuracy: 28.27\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 99/100 Step: 11830 Loss: 1.7968 Val Loss: 1.8910\n",
            "Train accuracy: 37.63 Val accuracy: 28.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 100/100 Step: 11960 Loss: 1.8082 Val Loss: 1.8901\n",
            "Train accuracy: 38.85 Val accuracy: 28.27\n",
            "\n",
            "----------\n",
            "Training complete in 2m 21s\n",
            "Best val Acc: 28.800000\n",
            "----------\n",
            "\n",
            "Epoch: 2/100 Step: 130 Loss: 1.9403 Val Loss: 1.9448\n",
            "Train accuracy: 19.40 Val accuracy: 15.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 3/100 Step: 260 Loss: 1.9354 Val Loss: 1.9424\n",
            "Train accuracy: 19.00 Val accuracy: 18.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 4/100 Step: 390 Loss: 1.9365 Val Loss: 1.9406\n",
            "Train accuracy: 25.13 Val accuracy: 19.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 5/100 Step: 520 Loss: 1.9228 Val Loss: 1.9384\n",
            "Train accuracy: 25.75 Val accuracy: 21.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 6/100 Step: 650 Loss: 1.9196 Val Loss: 1.9363\n",
            "Train accuracy: 27.08 Val accuracy: 20.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 7/100 Step: 780 Loss: 1.9193 Val Loss: 1.9337\n",
            "Train accuracy: 28.10 Val accuracy: 20.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 8/100 Step: 910 Loss: 1.9235 Val Loss: 1.9308\n",
            "Train accuracy: 28.06 Val accuracy: 23.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 9/100 Step: 1040 Loss: 1.9095 Val Loss: 1.9277\n",
            "Train accuracy: 28.52 Val accuracy: 23.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 10/100 Step: 1170 Loss: 1.8866 Val Loss: 1.9247\n",
            "Train accuracy: 29.78 Val accuracy: 22.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 11/100 Step: 1300 Loss: 1.8685 Val Loss: 1.9209\n",
            "Train accuracy: 29.88 Val accuracy: 24.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 12/100 Step: 1430 Loss: 1.9065 Val Loss: 1.9172\n",
            "Train accuracy: 31.62 Val accuracy: 24.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 13/100 Step: 1560 Loss: 1.8913 Val Loss: 1.9136\n",
            "Train accuracy: 31.33 Val accuracy: 25.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 15/100 Step: 1690 Loss: 1.8737 Val Loss: 1.9097\n",
            "Train accuracy: 38.80 Val accuracy: 26.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 16/100 Step: 1820 Loss: 1.8557 Val Loss: 1.9054\n",
            "Train accuracy: 35.50 Val accuracy: 26.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 17/100 Step: 1950 Loss: 1.8091 Val Loss: 1.9016\n",
            "Train accuracy: 34.07 Val accuracy: 27.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 18/100 Step: 2080 Loss: 1.8089 Val Loss: 1.8975\n",
            "Train accuracy: 35.95 Val accuracy: 27.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 19/100 Step: 2210 Loss: 1.8387 Val Loss: 1.8934\n",
            "Train accuracy: 36.88 Val accuracy: 27.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 20/100 Step: 2340 Loss: 1.8285 Val Loss: 1.8895\n",
            "Train accuracy: 37.67 Val accuracy: 28.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 21/100 Step: 2470 Loss: 1.8377 Val Loss: 1.8854\n",
            "Train accuracy: 38.40 Val accuracy: 28.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 22/100 Step: 2600 Loss: 1.9105 Val Loss: 1.8819\n",
            "Train accuracy: 39.23 Val accuracy: 28.80\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 23/100 Step: 2730 Loss: 1.7775 Val Loss: 1.8776\n",
            "Train accuracy: 40.62 Val accuracy: 29.07\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 24/100 Step: 2860 Loss: 1.8862 Val Loss: 1.8742\n",
            "Train accuracy: 41.20 Val accuracy: 29.73\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 25/100 Step: 2990 Loss: 1.8301 Val Loss: 1.8708\n",
            "Train accuracy: 42.07 Val accuracy: 29.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 26/100 Step: 3120 Loss: 1.8015 Val Loss: 1.8669\n",
            "Train accuracy: 42.83 Val accuracy: 29.87\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 28/100 Step: 3250 Loss: 1.8030 Val Loss: 1.8638\n",
            "Train accuracy: 43.60 Val accuracy: 30.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 29/100 Step: 3380 Loss: 1.7150 Val Loss: 1.8609\n",
            "Train accuracy: 41.90 Val accuracy: 30.13\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 30/100 Step: 3510 Loss: 1.8010 Val Loss: 1.8567\n",
            "Train accuracy: 46.80 Val accuracy: 31.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 31/100 Step: 3640 Loss: 1.7341 Val Loss: 1.8536\n",
            "Train accuracy: 49.25 Val accuracy: 30.93\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 32/100 Step: 3770 Loss: 1.8049 Val Loss: 1.8496\n",
            "Train accuracy: 48.16 Val accuracy: 31.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 33/100 Step: 3900 Loss: 1.7234 Val Loss: 1.8466\n",
            "Train accuracy: 47.93 Val accuracy: 31.87\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 34/100 Step: 4030 Loss: 1.7688 Val Loss: 1.8436\n",
            "Train accuracy: 48.51 Val accuracy: 32.00\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 35/100 Step: 4160 Loss: 1.7935 Val Loss: 1.8398\n",
            "Train accuracy: 50.10 Val accuracy: 32.80\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 36/100 Step: 4290 Loss: 1.7816 Val Loss: 1.8371\n",
            "Train accuracy: 49.80 Val accuracy: 33.47\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 37/100 Step: 4420 Loss: 1.6632 Val Loss: 1.8336\n",
            "Train accuracy: 51.14 Val accuracy: 33.60\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 38/100 Step: 4550 Loss: 1.7253 Val Loss: 1.8296\n",
            "Train accuracy: 51.67 Val accuracy: 34.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 39/100 Step: 4680 Loss: 1.6546 Val Loss: 1.8269\n",
            "Train accuracy: 52.70 Val accuracy: 34.00\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 41/100 Step: 4810 Loss: 1.7732 Val Loss: 1.8241\n",
            "Train accuracy: 55.00 Val accuracy: 34.40\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 42/100 Step: 4940 Loss: 1.5309 Val Loss: 1.8208\n",
            "Train accuracy: 54.50 Val accuracy: 35.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 43/100 Step: 5070 Loss: 1.7099 Val Loss: 1.8177\n",
            "Train accuracy: 55.60 Val accuracy: 34.93\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 44/100 Step: 5200 Loss: 1.5746 Val Loss: 1.8139\n",
            "Train accuracy: 56.20 Val accuracy: 35.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 45/100 Step: 5330 Loss: 1.6723 Val Loss: 1.8107\n",
            "Train accuracy: 57.28 Val accuracy: 35.73\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 46/100 Step: 5460 Loss: 1.6492 Val Loss: 1.8072\n",
            "Train accuracy: 58.47 Val accuracy: 37.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 47/100 Step: 5590 Loss: 1.6065 Val Loss: 1.8052\n",
            "Train accuracy: 59.60 Val accuracy: 36.53\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 48/100 Step: 5720 Loss: 1.6065 Val Loss: 1.8009\n",
            "Train accuracy: 60.02 Val accuracy: 37.60\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 49/100 Step: 5850 Loss: 1.6714 Val Loss: 1.7975\n",
            "Train accuracy: 60.67 Val accuracy: 38.13\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 50/100 Step: 5980 Loss: 1.6847 Val Loss: 1.7947\n",
            "Train accuracy: 61.52 Val accuracy: 38.80\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 51/100 Step: 6110 Loss: 1.6610 Val Loss: 1.7907\n",
            "Train accuracy: 62.49 Val accuracy: 39.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 52/100 Step: 6240 Loss: 1.6054 Val Loss: 1.7872\n",
            "Train accuracy: 63.25 Val accuracy: 39.60\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 54/100 Step: 6370 Loss: 1.6506 Val Loss: 1.7845\n",
            "Train accuracy: 62.40 Val accuracy: 40.00\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 55/100 Step: 6500 Loss: 1.6891 Val Loss: 1.7817\n",
            "Train accuracy: 64.20 Val accuracy: 40.27\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 56/100 Step: 6630 Loss: 1.5291 Val Loss: 1.7785\n",
            "Train accuracy: 66.47 Val accuracy: 40.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 57/100 Step: 6760 Loss: 1.5730 Val Loss: 1.7753\n",
            "Train accuracy: 65.80 Val accuracy: 40.27\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 58/100 Step: 6890 Loss: 1.6620 Val Loss: 1.7732\n",
            "Train accuracy: 66.40 Val accuracy: 40.93\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 59/100 Step: 7020 Loss: 1.6664 Val Loss: 1.7714\n",
            "Train accuracy: 67.57 Val accuracy: 41.20\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 60/100 Step: 7150 Loss: 1.5905 Val Loss: 1.7683\n",
            "Train accuracy: 69.09 Val accuracy: 41.73\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 61/100 Step: 7280 Loss: 1.5090 Val Loss: 1.7651\n",
            "Train accuracy: 68.85 Val accuracy: 42.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 62/100 Step: 7410 Loss: 1.4697 Val Loss: 1.7632\n",
            "Train accuracy: 69.09 Val accuracy: 41.73\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 63/100 Step: 7540 Loss: 1.6737 Val Loss: 1.7622\n",
            "Train accuracy: 69.44 Val accuracy: 42.13\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 64/100 Step: 7670 Loss: 1.5484 Val Loss: 1.7588\n",
            "Train accuracy: 70.55 Val accuracy: 42.27\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 65/100 Step: 7800 Loss: 1.5816 Val Loss: 1.7569\n",
            "Train accuracy: 70.82 Val accuracy: 42.67\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 67/100 Step: 7930 Loss: 1.5993 Val Loss: 1.7549\n",
            "Train accuracy: 70.00 Val accuracy: 42.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 68/100 Step: 8060 Loss: 1.4734 Val Loss: 1.7531\n",
            "Train accuracy: 72.10 Val accuracy: 42.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 69/100 Step: 8190 Loss: 1.4152 Val Loss: 1.7501\n",
            "Train accuracy: 74.13 Val accuracy: 42.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 70/100 Step: 8320 Loss: 1.5260 Val Loss: 1.7497\n",
            "Train accuracy: 74.30 Val accuracy: 42.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 71/100 Step: 8450 Loss: 1.5310 Val Loss: 1.7488\n",
            "Train accuracy: 74.08 Val accuracy: 42.40\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 72/100 Step: 8580 Loss: 1.4170 Val Loss: 1.7448\n",
            "Train accuracy: 74.27 Val accuracy: 43.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 73/100 Step: 8710 Loss: 1.6205 Val Loss: 1.7443\n",
            "Train accuracy: 73.86 Val accuracy: 43.07\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 74/100 Step: 8840 Loss: 1.4053 Val Loss: 1.7426\n",
            "Train accuracy: 75.00 Val accuracy: 43.33\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 75/100 Step: 8970 Loss: 1.5984 Val Loss: 1.7419\n",
            "Train accuracy: 74.47 Val accuracy: 43.47\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 76/100 Step: 9100 Loss: 1.4925 Val Loss: 1.7393\n",
            "Train accuracy: 75.36 Val accuracy: 43.47\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 77/100 Step: 9230 Loss: 1.5020 Val Loss: 1.7387\n",
            "Train accuracy: 75.25 Val accuracy: 43.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 78/100 Step: 9360 Loss: 1.3765 Val Loss: 1.7373\n",
            "Train accuracy: 75.77 Val accuracy: 43.33\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 80/100 Step: 9490 Loss: 1.5041 Val Loss: 1.7367\n",
            "Train accuracy: 78.40 Val accuracy: 44.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 81/100 Step: 9620 Loss: 1.5223 Val Loss: 1.7348\n",
            "Train accuracy: 75.90 Val accuracy: 43.47\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 82/100 Step: 9750 Loss: 1.4437 Val Loss: 1.7339\n",
            "Train accuracy: 76.87 Val accuracy: 43.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 83/100 Step: 9880 Loss: 1.3739 Val Loss: 1.7329\n",
            "Train accuracy: 77.80 Val accuracy: 44.00\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 84/100 Step: 10010 Loss: 1.4865 Val Loss: 1.7313\n",
            "Train accuracy: 77.28 Val accuracy: 44.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 85/100 Step: 10140 Loss: 1.4184 Val Loss: 1.7324\n",
            "Train accuracy: 77.97 Val accuracy: 44.27\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 86/100 Step: 10270 Loss: 1.5059 Val Loss: 1.7296\n",
            "Train accuracy: 77.51 Val accuracy: 44.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 87/100 Step: 10400 Loss: 1.4220 Val Loss: 1.7293\n",
            "Train accuracy: 77.95 Val accuracy: 44.93\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 88/100 Step: 10530 Loss: 1.4098 Val Loss: 1.7293\n",
            "Train accuracy: 78.20 Val accuracy: 45.33\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 89/100 Step: 10660 Loss: 1.4417 Val Loss: 1.7274\n",
            "Train accuracy: 78.12 Val accuracy: 45.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 90/100 Step: 10790 Loss: 1.3438 Val Loss: 1.7265\n",
            "Train accuracy: 78.65 Val accuracy: 45.87\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 91/100 Step: 10920 Loss: 1.4850 Val Loss: 1.7254\n",
            "Train accuracy: 78.80 Val accuracy: 46.13\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 93/100 Step: 11050 Loss: 1.5287 Val Loss: 1.7250\n",
            "Train accuracy: 81.80 Val accuracy: 46.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 94/100 Step: 11180 Loss: 1.4071 Val Loss: 1.7240\n",
            "Train accuracy: 78.10 Val accuracy: 46.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 95/100 Step: 11310 Loss: 1.3935 Val Loss: 1.7231\n",
            "Train accuracy: 80.53 Val accuracy: 46.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 96/100 Step: 11440 Loss: 1.3447 Val Loss: 1.7226\n",
            "Train accuracy: 79.10 Val accuracy: 46.27\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 97/100 Step: 11570 Loss: 1.4007 Val Loss: 1.7215\n",
            "Train accuracy: 79.24 Val accuracy: 46.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 98/100 Step: 11700 Loss: 1.4580 Val Loss: 1.7210\n",
            "Train accuracy: 79.10 Val accuracy: 46.00\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 99/100 Step: 11830 Loss: 1.3964 Val Loss: 1.7204\n",
            "Train accuracy: 79.94 Val accuracy: 46.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 100/100 Step: 11960 Loss: 1.4127 Val Loss: 1.7201\n",
            "Train accuracy: 79.75 Val accuracy: 46.40\n",
            "\n",
            "----------\n",
            "Training complete in 4m 40s\n",
            "Best val Acc: 46.533333\n",
            "----------\n",
            "\n",
            "Epoch: 2/100 Step: 130 Loss: 1.9367 Val Loss: 1.9428\n",
            "Train accuracy: 20.40 Val accuracy: 16.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 3/100 Step: 260 Loss: 1.9417 Val Loss: 1.9386\n",
            "Train accuracy: 24.10 Val accuracy: 18.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 4/100 Step: 390 Loss: 1.9275 Val Loss: 1.9335\n",
            "Train accuracy: 24.33 Val accuracy: 19.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 5/100 Step: 520 Loss: 1.9100 Val Loss: 1.9275\n",
            "Train accuracy: 25.55 Val accuracy: 21.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 6/100 Step: 650 Loss: 1.8799 Val Loss: 1.9213\n",
            "Train accuracy: 28.20 Val accuracy: 24.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 7/100 Step: 780 Loss: 1.9012 Val Loss: 1.9140\n",
            "Train accuracy: 29.97 Val accuracy: 27.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 8/100 Step: 910 Loss: 1.8894 Val Loss: 1.9072\n",
            "Train accuracy: 32.86 Val accuracy: 27.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 9/100 Step: 1040 Loss: 1.8463 Val Loss: 1.9003\n",
            "Train accuracy: 32.70 Val accuracy: 26.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 10/100 Step: 1170 Loss: 1.8005 Val Loss: 1.8935\n",
            "Train accuracy: 36.29 Val accuracy: 27.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 11/100 Step: 1300 Loss: 1.7945 Val Loss: 1.8863\n",
            "Train accuracy: 36.16 Val accuracy: 28.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 12/100 Step: 1430 Loss: 1.8199 Val Loss: 1.8778\n",
            "Train accuracy: 39.27 Val accuracy: 29.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 13/100 Step: 1560 Loss: 1.8076 Val Loss: 1.8709\n",
            "Train accuracy: 39.53 Val accuracy: 29.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 15/100 Step: 1690 Loss: 1.8299 Val Loss: 1.8637\n",
            "Train accuracy: 40.00 Val accuracy: 30.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 16/100 Step: 1820 Loss: 1.8261 Val Loss: 1.8590\n",
            "Train accuracy: 40.10 Val accuracy: 30.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 17/100 Step: 1950 Loss: 1.7731 Val Loss: 1.8490\n",
            "Train accuracy: 44.20 Val accuracy: 31.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 18/100 Step: 2080 Loss: 1.7184 Val Loss: 1.8419\n",
            "Train accuracy: 47.00 Val accuracy: 32.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 19/100 Step: 2210 Loss: 1.7573 Val Loss: 1.8359\n",
            "Train accuracy: 49.12 Val accuracy: 32.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 20/100 Step: 2340 Loss: 1.7707 Val Loss: 1.8280\n",
            "Train accuracy: 50.47 Val accuracy: 35.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 21/100 Step: 2470 Loss: 1.7569 Val Loss: 1.8221\n",
            "Train accuracy: 52.51 Val accuracy: 35.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 22/100 Step: 2600 Loss: 1.7975 Val Loss: 1.8157\n",
            "Train accuracy: 53.90 Val accuracy: 35.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 23/100 Step: 2730 Loss: 1.6936 Val Loss: 1.8083\n",
            "Train accuracy: 55.71 Val accuracy: 37.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 24/100 Step: 2860 Loss: 1.6148 Val Loss: 1.8008\n",
            "Train accuracy: 56.70 Val accuracy: 38.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 25/100 Step: 2990 Loss: 1.6826 Val Loss: 1.7960\n",
            "Train accuracy: 59.09 Val accuracy: 39.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 26/100 Step: 3120 Loss: 1.6876 Val Loss: 1.7901\n",
            "Train accuracy: 60.63 Val accuracy: 40.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 28/100 Step: 3250 Loss: 1.6489 Val Loss: 1.7844\n",
            "Train accuracy: 61.40 Val accuracy: 40.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 29/100 Step: 3380 Loss: 1.5468 Val Loss: 1.7784\n",
            "Train accuracy: 66.50 Val accuracy: 41.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 30/100 Step: 3510 Loss: 1.6036 Val Loss: 1.7754\n",
            "Train accuracy: 65.53 Val accuracy: 41.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 31/100 Step: 3640 Loss: 1.5750 Val Loss: 1.7698\n",
            "Train accuracy: 67.05 Val accuracy: 40.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 32/100 Step: 3770 Loss: 1.5814 Val Loss: 1.7673\n",
            "Train accuracy: 68.84 Val accuracy: 42.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 33/100 Step: 3900 Loss: 1.5606 Val Loss: 1.7617\n",
            "Train accuracy: 69.17 Val accuracy: 42.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 34/100 Step: 4030 Loss: 1.6100 Val Loss: 1.7577\n",
            "Train accuracy: 70.26 Val accuracy: 42.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 35/100 Step: 4160 Loss: 1.5033 Val Loss: 1.7528\n",
            "Train accuracy: 71.15 Val accuracy: 43.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 36/100 Step: 4290 Loss: 1.4084 Val Loss: 1.7511\n",
            "Train accuracy: 71.82 Val accuracy: 44.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 37/100 Step: 4420 Loss: 1.4534 Val Loss: 1.7500\n",
            "Train accuracy: 72.48 Val accuracy: 43.47\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 38/100 Step: 4550 Loss: 1.5124 Val Loss: 1.7469\n",
            "Train accuracy: 73.51 Val accuracy: 43.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 39/100 Step: 4680 Loss: 1.5050 Val Loss: 1.7441\n",
            "Train accuracy: 74.17 Val accuracy: 44.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 41/100 Step: 4810 Loss: 1.3954 Val Loss: 1.7427\n",
            "Train accuracy: 74.00 Val accuracy: 44.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 42/100 Step: 4940 Loss: 1.3445 Val Loss: 1.7399\n",
            "Train accuracy: 75.30 Val accuracy: 44.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 43/100 Step: 5070 Loss: 1.4934 Val Loss: 1.7378\n",
            "Train accuracy: 75.53 Val accuracy: 44.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 44/100 Step: 5200 Loss: 1.5106 Val Loss: 1.7359\n",
            "Train accuracy: 76.95 Val accuracy: 44.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 45/100 Step: 5330 Loss: 1.4742 Val Loss: 1.7364\n",
            "Train accuracy: 77.68 Val accuracy: 44.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 46/100 Step: 5460 Loss: 1.4764 Val Loss: 1.7350\n",
            "Train accuracy: 78.57 Val accuracy: 44.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 47/100 Step: 5590 Loss: 1.4511 Val Loss: 1.7327\n",
            "Train accuracy: 77.63 Val accuracy: 44.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 48/100 Step: 5720 Loss: 1.4779 Val Loss: 1.7309\n",
            "Train accuracy: 78.05 Val accuracy: 45.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 49/100 Step: 5850 Loss: 1.4264 Val Loss: 1.7295\n",
            "Train accuracy: 79.56 Val accuracy: 45.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 50/100 Step: 5980 Loss: 1.4158 Val Loss: 1.7286\n",
            "Train accuracy: 79.72 Val accuracy: 44.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 51/100 Step: 6110 Loss: 1.3779 Val Loss: 1.7272\n",
            "Train accuracy: 79.67 Val accuracy: 45.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 52/100 Step: 6240 Loss: 1.3414 Val Loss: 1.7267\n",
            "Train accuracy: 79.92 Val accuracy: 44.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 54/100 Step: 6370 Loss: 1.4657 Val Loss: 1.7254\n",
            "Train accuracy: 79.00 Val accuracy: 46.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 55/100 Step: 6500 Loss: 1.4264 Val Loss: 1.7250\n",
            "Train accuracy: 79.80 Val accuracy: 46.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 56/100 Step: 6630 Loss: 1.4410 Val Loss: 1.7223\n",
            "Train accuracy: 82.40 Val accuracy: 46.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 57/100 Step: 6760 Loss: 1.4431 Val Loss: 1.7225\n",
            "Train accuracy: 81.35 Val accuracy: 46.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 58/100 Step: 6890 Loss: 1.3872 Val Loss: 1.7213\n",
            "Train accuracy: 82.16 Val accuracy: 46.53\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 59/100 Step: 7020 Loss: 1.4742 Val Loss: 1.7211\n",
            "Train accuracy: 80.40 Val accuracy: 47.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 60/100 Step: 7150 Loss: 1.3444 Val Loss: 1.7201\n",
            "Train accuracy: 81.40 Val accuracy: 46.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 61/100 Step: 7280 Loss: 1.4228 Val Loss: 1.7190\n",
            "Train accuracy: 81.33 Val accuracy: 46.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 62/100 Step: 7410 Loss: 1.3824 Val Loss: 1.7194\n",
            "Train accuracy: 82.20 Val accuracy: 46.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 63/100 Step: 7540 Loss: 1.3931 Val Loss: 1.7221\n",
            "Train accuracy: 87.30 Val accuracy: 47.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 64/100 Step: 7670 Loss: 1.3319 Val Loss: 1.7238\n",
            "Train accuracy: 88.53 Val accuracy: 45.87\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 65/100 Step: 7800 Loss: 1.2818 Val Loss: 1.7219\n",
            "Train accuracy: 89.50 Val accuracy: 47.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 67/100 Step: 7930 Loss: 1.2874 Val Loss: 1.7189\n",
            "Train accuracy: 90.20 Val accuracy: 46.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 68/100 Step: 8060 Loss: 1.3470 Val Loss: 1.7214\n",
            "Train accuracy: 91.50 Val accuracy: 46.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 69/100 Step: 8190 Loss: 1.3466 Val Loss: 1.7230\n",
            "Train accuracy: 91.80 Val accuracy: 45.33\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 70/100 Step: 8320 Loss: 1.3091 Val Loss: 1.7138\n",
            "Train accuracy: 93.20 Val accuracy: 48.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 71/100 Step: 8450 Loss: 1.3135 Val Loss: 1.7134\n",
            "Train accuracy: 93.36 Val accuracy: 47.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 72/100 Step: 8580 Loss: 1.3071 Val Loss: 1.7144\n",
            "Train accuracy: 93.83 Val accuracy: 47.47\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 73/100 Step: 8710 Loss: 1.3120 Val Loss: 1.7110\n",
            "Train accuracy: 94.26 Val accuracy: 48.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 74/100 Step: 8840 Loss: 1.2841 Val Loss: 1.7124\n",
            "Train accuracy: 94.88 Val accuracy: 47.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 75/100 Step: 8970 Loss: 1.3113 Val Loss: 1.7153\n",
            "Train accuracy: 94.76 Val accuracy: 46.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 76/100 Step: 9100 Loss: 1.2258 Val Loss: 1.7127\n",
            "Train accuracy: 95.12 Val accuracy: 47.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 77/100 Step: 9230 Loss: 1.2872 Val Loss: 1.7076\n",
            "Train accuracy: 95.35 Val accuracy: 48.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 78/100 Step: 9360 Loss: 1.2837 Val Loss: 1.7095\n",
            "Train accuracy: 95.58 Val accuracy: 48.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 80/100 Step: 9490 Loss: 1.3323 Val Loss: 1.7105\n",
            "Train accuracy: 95.00 Val accuracy: 48.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 81/100 Step: 9620 Loss: 1.3042 Val Loss: 1.7088\n",
            "Train accuracy: 96.60 Val accuracy: 48.13\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 82/100 Step: 9750 Loss: 1.2458 Val Loss: 1.7069\n",
            "Train accuracy: 96.33 Val accuracy: 48.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 83/100 Step: 9880 Loss: 1.2762 Val Loss: 1.7094\n",
            "Train accuracy: 96.60 Val accuracy: 47.33\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 84/100 Step: 10010 Loss: 1.2509 Val Loss: 1.7044\n",
            "Train accuracy: 96.72 Val accuracy: 49.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 85/100 Step: 10140 Loss: 1.2526 Val Loss: 1.7058\n",
            "Train accuracy: 96.67 Val accuracy: 48.67\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 86/100 Step: 10270 Loss: 1.2307 Val Loss: 1.7009\n",
            "Train accuracy: 96.86 Val accuracy: 49.60\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 87/100 Step: 10400 Loss: 1.2420 Val Loss: 1.7006\n",
            "Train accuracy: 96.88 Val accuracy: 50.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 88/100 Step: 10530 Loss: 1.2321 Val Loss: 1.7013\n",
            "Train accuracy: 96.91 Val accuracy: 50.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 89/100 Step: 10660 Loss: 1.2285 Val Loss: 1.7041\n",
            "Train accuracy: 97.04 Val accuracy: 48.40\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 90/100 Step: 10790 Loss: 1.2267 Val Loss: 1.6995\n",
            "Train accuracy: 97.11 Val accuracy: 50.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 91/100 Step: 10920 Loss: 1.2152 Val Loss: 1.6963\n",
            "Train accuracy: 97.22 Val accuracy: 50.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 93/100 Step: 11050 Loss: 1.2232 Val Loss: 1.6968\n",
            "Train accuracy: 96.40 Val accuracy: 50.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 94/100 Step: 11180 Loss: 1.2078 Val Loss: 1.6971\n",
            "Train accuracy: 97.00 Val accuracy: 49.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 95/100 Step: 11310 Loss: 1.2320 Val Loss: 1.7023\n",
            "Train accuracy: 97.27 Val accuracy: 48.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 96/100 Step: 11440 Loss: 1.2574 Val Loss: 1.6953\n",
            "Train accuracy: 97.55 Val accuracy: 50.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 97/100 Step: 11570 Loss: 1.1874 Val Loss: 1.6953\n",
            "Train accuracy: 97.88 Val accuracy: 49.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 98/100 Step: 11700 Loss: 1.1934 Val Loss: 1.6947\n",
            "Train accuracy: 97.43 Val accuracy: 49.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 99/100 Step: 11830 Loss: 1.2261 Val Loss: 1.6950\n",
            "Train accuracy: 97.71 Val accuracy: 49.73\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 100/100 Step: 11960 Loss: 1.2403 Val Loss: 1.6903\n",
            "Train accuracy: 97.58 Val accuracy: 50.40\n",
            "\n",
            "----------\n",
            "Training complete in 6m 59s\n",
            "Best val Acc: 50.400000\n",
            "----------\n",
            "\n",
            "Epoch: 2/100 Step: 130 Loss: 1.9304 Val Loss: 1.9423\n",
            "Train accuracy: 17.20 Val accuracy: 16.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 3/100 Step: 260 Loss: 1.9101 Val Loss: 1.9320\n",
            "Train accuracy: 27.40 Val accuracy: 19.47\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 4/100 Step: 390 Loss: 1.9142 Val Loss: 1.9182\n",
            "Train accuracy: 30.20 Val accuracy: 23.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 5/100 Step: 520 Loss: 1.8019 Val Loss: 1.9036\n",
            "Train accuracy: 33.60 Val accuracy: 24.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 6/100 Step: 650 Loss: 1.8682 Val Loss: 1.8871\n",
            "Train accuracy: 38.28 Val accuracy: 27.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 7/100 Step: 780 Loss: 1.8356 Val Loss: 1.8732\n",
            "Train accuracy: 39.37 Val accuracy: 28.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 8/100 Step: 910 Loss: 1.7507 Val Loss: 1.8569\n",
            "Train accuracy: 43.26 Val accuracy: 30.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 9/100 Step: 1040 Loss: 1.7913 Val Loss: 1.8417\n",
            "Train accuracy: 45.57 Val accuracy: 32.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 10/100 Step: 1170 Loss: 1.7539 Val Loss: 1.8308\n",
            "Train accuracy: 48.67 Val accuracy: 33.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 11/100 Step: 1300 Loss: 1.6589 Val Loss: 1.8190\n",
            "Train accuracy: 51.80 Val accuracy: 35.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 12/100 Step: 1430 Loss: 1.6543 Val Loss: 1.8035\n",
            "Train accuracy: 55.29 Val accuracy: 39.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 13/100 Step: 1560 Loss: 1.6183 Val Loss: 1.7949\n",
            "Train accuracy: 58.15 Val accuracy: 39.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 15/100 Step: 1690 Loss: 1.5335 Val Loss: 1.7857\n",
            "Train accuracy: 63.00 Val accuracy: 39.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 16/100 Step: 1820 Loss: 1.5840 Val Loss: 1.7765\n",
            "Train accuracy: 63.10 Val accuracy: 42.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 17/100 Step: 1950 Loss: 1.5430 Val Loss: 1.7688\n",
            "Train accuracy: 69.80 Val accuracy: 41.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 18/100 Step: 2080 Loss: 1.5928 Val Loss: 1.7634\n",
            "Train accuracy: 69.65 Val accuracy: 42.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 19/100 Step: 2210 Loss: 1.4553 Val Loss: 1.7562\n",
            "Train accuracy: 71.64 Val accuracy: 44.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 20/100 Step: 2340 Loss: 1.6029 Val Loss: 1.7518\n",
            "Train accuracy: 73.50 Val accuracy: 43.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 21/100 Step: 2470 Loss: 1.4799 Val Loss: 1.7450\n",
            "Train accuracy: 74.74 Val accuracy: 44.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 22/100 Step: 2600 Loss: 1.4643 Val Loss: 1.7430\n",
            "Train accuracy: 75.90 Val accuracy: 43.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 23/100 Step: 2730 Loss: 1.4353 Val Loss: 1.7378\n",
            "Train accuracy: 76.36 Val accuracy: 44.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 24/100 Step: 2860 Loss: 1.5195 Val Loss: 1.7365\n",
            "Train accuracy: 77.62 Val accuracy: 43.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 25/100 Step: 2990 Loss: 1.3271 Val Loss: 1.7324\n",
            "Train accuracy: 78.67 Val accuracy: 45.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 26/100 Step: 3120 Loss: 1.4116 Val Loss: 1.7294\n",
            "Train accuracy: 79.15 Val accuracy: 44.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 28/100 Step: 3250 Loss: 1.4498 Val Loss: 1.7276\n",
            "Train accuracy: 74.80 Val accuracy: 44.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 29/100 Step: 3380 Loss: 1.2891 Val Loss: 1.7247\n",
            "Train accuracy: 82.00 Val accuracy: 44.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 30/100 Step: 3510 Loss: 1.3653 Val Loss: 1.7230\n",
            "Train accuracy: 81.40 Val accuracy: 45.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 31/100 Step: 3640 Loss: 1.3752 Val Loss: 1.7216\n",
            "Train accuracy: 81.95 Val accuracy: 45.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 32/100 Step: 3770 Loss: 1.3715 Val Loss: 1.7200\n",
            "Train accuracy: 80.72 Val accuracy: 45.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 33/100 Step: 3900 Loss: 1.3935 Val Loss: 1.7184\n",
            "Train accuracy: 82.63 Val accuracy: 45.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 34/100 Step: 4030 Loss: 1.3301 Val Loss: 1.7253\n",
            "Train accuracy: 87.31 Val accuracy: 46.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 35/100 Step: 4160 Loss: 1.2972 Val Loss: 1.7246\n",
            "Train accuracy: 90.40 Val accuracy: 46.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 36/100 Step: 4290 Loss: 1.2853 Val Loss: 1.7304\n",
            "Train accuracy: 91.24 Val accuracy: 45.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 37/100 Step: 4420 Loss: 1.3412 Val Loss: 1.7244\n",
            "Train accuracy: 92.74 Val accuracy: 46.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 38/100 Step: 4550 Loss: 1.3506 Val Loss: 1.7158\n",
            "Train accuracy: 93.40 Val accuracy: 46.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 39/100 Step: 4680 Loss: 1.2835 Val Loss: 1.7165\n",
            "Train accuracy: 94.17 Val accuracy: 46.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 41/100 Step: 4810 Loss: 1.2957 Val Loss: 1.7147\n",
            "Train accuracy: 94.40 Val accuracy: 47.47\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 42/100 Step: 4940 Loss: 1.2631 Val Loss: 1.7130\n",
            "Train accuracy: 96.20 Val accuracy: 47.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 43/100 Step: 5070 Loss: 1.2829 Val Loss: 1.7110\n",
            "Train accuracy: 95.73 Val accuracy: 46.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 44/100 Step: 5200 Loss: 1.2626 Val Loss: 1.7059\n",
            "Train accuracy: 96.15 Val accuracy: 46.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 45/100 Step: 5330 Loss: 1.2449 Val Loss: 1.7047\n",
            "Train accuracy: 95.72 Val accuracy: 47.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 46/100 Step: 5460 Loss: 1.2223 Val Loss: 1.7019\n",
            "Train accuracy: 96.37 Val accuracy: 48.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 47/100 Step: 5590 Loss: 1.2465 Val Loss: 1.7034\n",
            "Train accuracy: 96.80 Val accuracy: 47.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 48/100 Step: 5720 Loss: 1.2300 Val Loss: 1.6970\n",
            "Train accuracy: 96.83 Val accuracy: 48.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 49/100 Step: 5850 Loss: 1.2204 Val Loss: 1.6972\n",
            "Train accuracy: 96.80 Val accuracy: 47.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 50/100 Step: 5980 Loss: 1.2083 Val Loss: 1.6968\n",
            "Train accuracy: 96.96 Val accuracy: 47.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 51/100 Step: 6110 Loss: 1.2010 Val Loss: 1.7005\n",
            "Train accuracy: 96.87 Val accuracy: 47.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 52/100 Step: 6240 Loss: 1.2150 Val Loss: 1.6933\n",
            "Train accuracy: 97.00 Val accuracy: 48.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 54/100 Step: 6370 Loss: 1.2371 Val Loss: 1.6981\n",
            "Train accuracy: 98.00 Val accuracy: 47.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 55/100 Step: 6500 Loss: 1.2125 Val Loss: 1.6927\n",
            "Train accuracy: 96.60 Val accuracy: 48.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 56/100 Step: 6630 Loss: 1.1984 Val Loss: 1.6925\n",
            "Train accuracy: 97.87 Val accuracy: 48.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 57/100 Step: 6760 Loss: 1.2070 Val Loss: 1.6911\n",
            "Train accuracy: 97.60 Val accuracy: 48.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 58/100 Step: 6890 Loss: 1.1783 Val Loss: 1.6915\n",
            "Train accuracy: 97.88 Val accuracy: 47.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 59/100 Step: 7020 Loss: 1.2197 Val Loss: 1.6920\n",
            "Train accuracy: 97.50 Val accuracy: 48.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 60/100 Step: 7150 Loss: 1.2199 Val Loss: 1.6892\n",
            "Train accuracy: 97.49 Val accuracy: 48.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 61/100 Step: 7280 Loss: 1.1818 Val Loss: 1.6887\n",
            "Train accuracy: 97.38 Val accuracy: 48.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 62/100 Step: 7410 Loss: 1.2142 Val Loss: 1.6860\n",
            "Train accuracy: 97.64 Val accuracy: 48.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 63/100 Step: 7540 Loss: 1.1762 Val Loss: 1.6843\n",
            "Train accuracy: 97.64 Val accuracy: 49.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 64/100 Step: 7670 Loss: 1.2170 Val Loss: 1.6865\n",
            "Train accuracy: 97.69 Val accuracy: 48.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 65/100 Step: 7800 Loss: 1.1810 Val Loss: 1.6845\n",
            "Train accuracy: 97.73 Val accuracy: 48.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 67/100 Step: 7930 Loss: 1.1937 Val Loss: 1.6852\n",
            "Train accuracy: 98.00 Val accuracy: 49.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 68/100 Step: 8060 Loss: 1.2123 Val Loss: 1.6844\n",
            "Train accuracy: 97.00 Val accuracy: 49.47\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 69/100 Step: 8190 Loss: 1.1931 Val Loss: 1.6815\n",
            "Train accuracy: 98.00 Val accuracy: 49.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 70/100 Step: 8320 Loss: 1.1965 Val Loss: 1.6825\n",
            "Train accuracy: 98.20 Val accuracy: 49.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 71/100 Step: 8450 Loss: 1.1939 Val Loss: 1.6803\n",
            "Train accuracy: 98.04 Val accuracy: 49.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 72/100 Step: 8580 Loss: 1.2105 Val Loss: 1.6812\n",
            "Train accuracy: 98.03 Val accuracy: 49.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 73/100 Step: 8710 Loss: 1.2121 Val Loss: 1.6799\n",
            "Train accuracy: 98.46 Val accuracy: 49.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 74/100 Step: 8840 Loss: 1.1769 Val Loss: 1.6807\n",
            "Train accuracy: 97.95 Val accuracy: 49.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 75/100 Step: 8970 Loss: 1.1940 Val Loss: 1.6817\n",
            "Train accuracy: 98.09 Val accuracy: 49.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 76/100 Step: 9100 Loss: 1.1729 Val Loss: 1.6815\n",
            "Train accuracy: 98.00 Val accuracy: 49.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 77/100 Step: 9230 Loss: 1.1908 Val Loss: 1.6784\n",
            "Train accuracy: 98.09 Val accuracy: 50.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 78/100 Step: 9360 Loss: 1.1903 Val Loss: 1.6801\n",
            "Train accuracy: 98.10 Val accuracy: 49.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 80/100 Step: 9490 Loss: 1.1918 Val Loss: 1.6780\n",
            "Train accuracy: 99.20 Val accuracy: 50.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 81/100 Step: 9620 Loss: 1.1733 Val Loss: 1.6791\n",
            "Train accuracy: 98.80 Val accuracy: 50.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 82/100 Step: 9750 Loss: 1.1736 Val Loss: 1.6784\n",
            "Train accuracy: 98.00 Val accuracy: 50.13\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 83/100 Step: 9880 Loss: 1.1899 Val Loss: 1.6783\n",
            "Train accuracy: 98.35 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 84/100 Step: 10010 Loss: 1.2082 Val Loss: 1.6781\n",
            "Train accuracy: 98.36 Val accuracy: 49.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 85/100 Step: 10140 Loss: 1.2344 Val Loss: 1.6763\n",
            "Train accuracy: 98.10 Val accuracy: 50.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 86/100 Step: 10270 Loss: 1.1706 Val Loss: 1.6780\n",
            "Train accuracy: 98.29 Val accuracy: 49.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 87/100 Step: 10400 Loss: 1.1709 Val Loss: 1.6777\n",
            "Train accuracy: 98.28 Val accuracy: 50.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 88/100 Step: 10530 Loss: 1.1903 Val Loss: 1.6758\n",
            "Train accuracy: 98.38 Val accuracy: 50.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 89/100 Step: 10660 Loss: 1.2086 Val Loss: 1.6779\n",
            "Train accuracy: 98.32 Val accuracy: 50.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 90/100 Step: 10790 Loss: 1.1763 Val Loss: 1.6779\n",
            "Train accuracy: 98.45 Val accuracy: 49.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 91/100 Step: 10920 Loss: 1.1723 Val Loss: 1.6759\n",
            "Train accuracy: 98.42 Val accuracy: 50.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 93/100 Step: 11050 Loss: 1.1695 Val Loss: 1.6767\n",
            "Train accuracy: 98.60 Val accuracy: 50.27\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 94/100 Step: 11180 Loss: 1.1710 Val Loss: 1.6752\n",
            "Train accuracy: 98.00 Val accuracy: 50.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 95/100 Step: 11310 Loss: 1.1897 Val Loss: 1.6754\n",
            "Train accuracy: 97.93 Val accuracy: 50.00\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 96/100 Step: 11440 Loss: 1.1701 Val Loss: 1.6746\n",
            "Train accuracy: 98.45 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 97/100 Step: 11570 Loss: 1.1887 Val Loss: 1.6754\n",
            "Train accuracy: 98.36 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 98/100 Step: 11700 Loss: 1.1893 Val Loss: 1.6752\n",
            "Train accuracy: 98.40 Val accuracy: 50.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 99/100 Step: 11830 Loss: 1.1695 Val Loss: 1.6737\n",
            "Train accuracy: 98.46 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 100/100 Step: 11960 Loss: 1.1696 Val Loss: 1.6752\n",
            "Train accuracy: 98.60 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "Training complete in 9m 17s\n",
            "Best val Acc: 50.933333\n",
            "----------\n",
            "\n",
            "Epoch: 2/100 Step: 130 Loss: 1.9055 Val Loss: 1.9311\n",
            "Train accuracy: 19.80 Val accuracy: 20.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 3/100 Step: 260 Loss: 1.8889 Val Loss: 1.8898\n",
            "Train accuracy: 33.50 Val accuracy: 28.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 4/100 Step: 390 Loss: 1.7465 Val Loss: 1.8572\n",
            "Train accuracy: 41.60 Val accuracy: 31.47\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 5/100 Step: 520 Loss: 1.7176 Val Loss: 1.8185\n",
            "Train accuracy: 48.10 Val accuracy: 36.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 6/100 Step: 650 Loss: 1.5999 Val Loss: 1.7876\n",
            "Train accuracy: 56.92 Val accuracy: 40.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 7/100 Step: 780 Loss: 1.5489 Val Loss: 1.7615\n",
            "Train accuracy: 62.40 Val accuracy: 42.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 8/100 Step: 910 Loss: 1.5800 Val Loss: 1.7513\n",
            "Train accuracy: 68.34 Val accuracy: 42.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 9/100 Step: 1040 Loss: 1.5270 Val Loss: 1.7438\n",
            "Train accuracy: 71.97 Val accuracy: 43.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 10/100 Step: 1170 Loss: 1.4398 Val Loss: 1.7347\n",
            "Train accuracy: 75.93 Val accuracy: 44.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 11/100 Step: 1300 Loss: 1.5099 Val Loss: 1.7261\n",
            "Train accuracy: 77.72 Val accuracy: 45.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 12/100 Step: 1430 Loss: 1.4405 Val Loss: 1.7216\n",
            "Train accuracy: 78.80 Val accuracy: 45.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 13/100 Step: 1560 Loss: 1.4448 Val Loss: 1.7178\n",
            "Train accuracy: 80.40 Val accuracy: 45.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 15/100 Step: 1690 Loss: 1.3047 Val Loss: 1.7151\n",
            "Train accuracy: 84.80 Val accuracy: 46.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 16/100 Step: 1820 Loss: 1.2921 Val Loss: 1.7098\n",
            "Train accuracy: 91.10 Val accuracy: 46.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 17/100 Step: 1950 Loss: 1.2962 Val Loss: 1.7115\n",
            "Train accuracy: 93.53 Val accuracy: 47.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 18/100 Step: 2080 Loss: 1.2148 Val Loss: 1.7030\n",
            "Train accuracy: 95.70 Val accuracy: 48.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 19/100 Step: 2210 Loss: 1.2166 Val Loss: 1.6968\n",
            "Train accuracy: 96.48 Val accuracy: 49.47\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 20/100 Step: 2340 Loss: 1.2359 Val Loss: 1.7007\n",
            "Train accuracy: 96.30 Val accuracy: 47.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 21/100 Step: 2470 Loss: 1.2702 Val Loss: 1.6966\n",
            "Train accuracy: 96.83 Val accuracy: 47.47\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 22/100 Step: 2600 Loss: 1.2228 Val Loss: 1.6911\n",
            "Train accuracy: 97.25 Val accuracy: 48.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 23/100 Step: 2730 Loss: 1.2267 Val Loss: 1.6902\n",
            "Train accuracy: 97.07 Val accuracy: 47.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 24/100 Step: 2860 Loss: 1.1849 Val Loss: 1.6889\n",
            "Train accuracy: 97.46 Val accuracy: 47.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 25/100 Step: 2990 Loss: 1.2005 Val Loss: 1.6895\n",
            "Train accuracy: 97.62 Val accuracy: 47.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 26/100 Step: 3120 Loss: 1.1754 Val Loss: 1.6843\n",
            "Train accuracy: 97.70 Val accuracy: 48.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 28/100 Step: 3250 Loss: 1.1942 Val Loss: 1.6840\n",
            "Train accuracy: 98.40 Val accuracy: 47.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 29/100 Step: 3380 Loss: 1.1762 Val Loss: 1.6817\n",
            "Train accuracy: 98.50 Val accuracy: 48.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 30/100 Step: 3510 Loss: 1.1745 Val Loss: 1.6813\n",
            "Train accuracy: 98.33 Val accuracy: 48.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 31/100 Step: 3640 Loss: 1.1927 Val Loss: 1.6773\n",
            "Train accuracy: 98.20 Val accuracy: 49.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 32/100 Step: 3770 Loss: 1.2131 Val Loss: 1.6797\n",
            "Train accuracy: 97.92 Val accuracy: 48.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 33/100 Step: 3900 Loss: 1.1902 Val Loss: 1.6780\n",
            "Train accuracy: 98.43 Val accuracy: 48.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 34/100 Step: 4030 Loss: 1.2270 Val Loss: 1.6761\n",
            "Train accuracy: 98.43 Val accuracy: 48.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 35/100 Step: 4160 Loss: 1.2126 Val Loss: 1.6743\n",
            "Train accuracy: 98.35 Val accuracy: 48.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 36/100 Step: 4290 Loss: 1.1708 Val Loss: 1.6737\n",
            "Train accuracy: 98.49 Val accuracy: 49.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 37/100 Step: 4420 Loss: 1.1695 Val Loss: 1.6752\n",
            "Train accuracy: 98.48 Val accuracy: 48.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 38/100 Step: 4550 Loss: 1.1902 Val Loss: 1.6704\n",
            "Train accuracy: 98.60 Val accuracy: 50.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 39/100 Step: 4680 Loss: 1.2102 Val Loss: 1.6729\n",
            "Train accuracy: 98.60 Val accuracy: 49.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 41/100 Step: 4810 Loss: 1.1898 Val Loss: 1.6719\n",
            "Train accuracy: 98.80 Val accuracy: 49.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 42/100 Step: 4940 Loss: 1.1699 Val Loss: 1.6704\n",
            "Train accuracy: 99.20 Val accuracy: 50.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 43/100 Step: 5070 Loss: 1.2083 Val Loss: 1.6691\n",
            "Train accuracy: 98.73 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 44/100 Step: 5200 Loss: 1.1703 Val Loss: 1.6712\n",
            "Train accuracy: 98.80 Val accuracy: 49.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 45/100 Step: 5330 Loss: 1.2085 Val Loss: 1.6692\n",
            "Train accuracy: 98.48 Val accuracy: 49.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 46/100 Step: 5460 Loss: 1.1681 Val Loss: 1.6695\n",
            "Train accuracy: 98.87 Val accuracy: 49.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 47/100 Step: 5590 Loss: 1.1873 Val Loss: 1.6690\n",
            "Train accuracy: 98.91 Val accuracy: 50.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 48/100 Step: 5720 Loss: 1.1686 Val Loss: 1.6675\n",
            "Train accuracy: 99.00 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 49/100 Step: 5850 Loss: 1.1682 Val Loss: 1.6675\n",
            "Train accuracy: 98.87 Val accuracy: 49.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 50/100 Step: 5980 Loss: 1.1677 Val Loss: 1.6660\n",
            "Train accuracy: 98.90 Val accuracy: 50.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 51/100 Step: 6110 Loss: 1.1680 Val Loss: 1.6676\n",
            "Train accuracy: 99.00 Val accuracy: 50.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 52/100 Step: 6240 Loss: 1.1677 Val Loss: 1.6669\n",
            "Train accuracy: 98.95 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 54/100 Step: 6370 Loss: 1.1865 Val Loss: 1.6663\n",
            "Train accuracy: 98.80 Val accuracy: 50.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 55/100 Step: 6500 Loss: 1.1679 Val Loss: 1.6661\n",
            "Train accuracy: 99.00 Val accuracy: 50.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 56/100 Step: 6630 Loss: 1.1678 Val Loss: 1.6672\n",
            "Train accuracy: 99.07 Val accuracy: 49.47\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 57/100 Step: 6760 Loss: 1.1875 Val Loss: 1.6652\n",
            "Train accuracy: 98.85 Val accuracy: 50.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 58/100 Step: 6890 Loss: 1.1670 Val Loss: 1.6656\n",
            "Train accuracy: 99.24 Val accuracy: 50.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 59/100 Step: 7020 Loss: 1.1679 Val Loss: 1.6658\n",
            "Train accuracy: 98.90 Val accuracy: 50.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 60/100 Step: 7150 Loss: 1.1676 Val Loss: 1.6649\n",
            "Train accuracy: 99.03 Val accuracy: 50.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 61/100 Step: 7280 Loss: 1.1872 Val Loss: 1.6653\n",
            "Train accuracy: 98.90 Val accuracy: 50.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 62/100 Step: 7410 Loss: 1.1672 Val Loss: 1.6648\n",
            "Train accuracy: 99.00 Val accuracy: 50.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 63/100 Step: 7540 Loss: 1.1675 Val Loss: 1.6653\n",
            "Train accuracy: 99.02 Val accuracy: 50.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 64/100 Step: 7670 Loss: 1.2038 Val Loss: 1.6646\n",
            "Train accuracy: 99.07 Val accuracy: 50.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 65/100 Step: 7800 Loss: 1.1669 Val Loss: 1.6655\n",
            "Train accuracy: 99.08 Val accuracy: 50.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 67/100 Step: 7930 Loss: 1.1869 Val Loss: 1.6648\n",
            "Train accuracy: 99.40 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 68/100 Step: 8060 Loss: 1.1875 Val Loss: 1.6640\n",
            "Train accuracy: 99.20 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 69/100 Step: 8190 Loss: 1.1861 Val Loss: 1.6646\n",
            "Train accuracy: 99.13 Val accuracy: 50.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 70/100 Step: 8320 Loss: 1.1669 Val Loss: 1.6638\n",
            "Train accuracy: 98.95 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 71/100 Step: 8450 Loss: 1.1868 Val Loss: 1.6642\n",
            "Train accuracy: 99.24 Val accuracy: 50.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 72/100 Step: 8580 Loss: 1.1866 Val Loss: 1.6641\n",
            "Train accuracy: 98.93 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 73/100 Step: 8710 Loss: 1.1672 Val Loss: 1.6646\n",
            "Train accuracy: 99.00 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 74/100 Step: 8840 Loss: 1.1670 Val Loss: 1.6634\n",
            "Train accuracy: 99.05 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 75/100 Step: 8970 Loss: 1.1673 Val Loss: 1.6630\n",
            "Train accuracy: 99.20 Val accuracy: 51.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 76/100 Step: 9100 Loss: 1.1870 Val Loss: 1.6633\n",
            "Train accuracy: 99.18 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 77/100 Step: 9230 Loss: 1.1667 Val Loss: 1.6635\n",
            "Train accuracy: 99.13 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 78/100 Step: 9360 Loss: 1.1667 Val Loss: 1.6629\n",
            "Train accuracy: 99.15 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 80/100 Step: 9490 Loss: 1.1855 Val Loss: 1.6628\n",
            "Train accuracy: 99.60 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 81/100 Step: 9620 Loss: 1.1667 Val Loss: 1.6632\n",
            "Train accuracy: 99.20 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 82/100 Step: 9750 Loss: 1.1666 Val Loss: 1.6624\n",
            "Train accuracy: 99.20 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 83/100 Step: 9880 Loss: 1.1669 Val Loss: 1.6627\n",
            "Train accuracy: 99.35 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 84/100 Step: 10010 Loss: 1.1853 Val Loss: 1.6624\n",
            "Train accuracy: 99.00 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 85/100 Step: 10140 Loss: 1.1671 Val Loss: 1.6626\n",
            "Train accuracy: 99.23 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 86/100 Step: 10270 Loss: 1.1665 Val Loss: 1.6626\n",
            "Train accuracy: 99.06 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 87/100 Step: 10400 Loss: 1.1820 Val Loss: 1.6620\n",
            "Train accuracy: 99.22 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 88/100 Step: 10530 Loss: 1.1664 Val Loss: 1.6621\n",
            "Train accuracy: 99.20 Val accuracy: 50.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 89/100 Step: 10660 Loss: 1.1664 Val Loss: 1.6622\n",
            "Train accuracy: 99.20 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 90/100 Step: 10790 Loss: 1.1667 Val Loss: 1.6623\n",
            "Train accuracy: 99.20 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 91/100 Step: 10920 Loss: 1.1663 Val Loss: 1.6622\n",
            "Train accuracy: 99.20 Val accuracy: 51.07\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 93/100 Step: 11050 Loss: 1.1664 Val Loss: 1.6617\n",
            "Train accuracy: 99.60 Val accuracy: 51.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 94/100 Step: 11180 Loss: 1.1864 Val Loss: 1.6620\n",
            "Train accuracy: 99.30 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 95/100 Step: 11310 Loss: 1.1665 Val Loss: 1.6612\n",
            "Train accuracy: 99.40 Val accuracy: 51.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 96/100 Step: 11440 Loss: 1.1861 Val Loss: 1.6616\n",
            "Train accuracy: 99.15 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 97/100 Step: 11570 Loss: 1.1664 Val Loss: 1.6616\n",
            "Train accuracy: 99.32 Val accuracy: 51.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 98/100 Step: 11700 Loss: 1.1841 Val Loss: 1.6610\n",
            "Train accuracy: 99.13 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 99/100 Step: 11830 Loss: 1.1664 Val Loss: 1.6611\n",
            "Train accuracy: 99.20 Val accuracy: 51.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 100/100 Step: 11960 Loss: 1.1664 Val Loss: 1.6612\n",
            "Train accuracy: 99.28 Val accuracy: 51.07\n",
            "\n",
            "----------\n",
            "Training complete in 11m 36s\n",
            "Best val Acc: 51.333333\n",
            "----------\n",
            "\n",
            "Epoch: 2/100 Step: 130 Loss: 1.8820 Val Loss: 1.9063\n",
            "Train accuracy: 27.20 Val accuracy: 24.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 3/100 Step: 260 Loss: 1.7487 Val Loss: 1.8344\n",
            "Train accuracy: 43.30 Val accuracy: 32.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 4/100 Step: 390 Loss: 1.6561 Val Loss: 1.7702\n",
            "Train accuracy: 56.60 Val accuracy: 41.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 5/100 Step: 520 Loss: 1.6035 Val Loss: 1.7396\n",
            "Train accuracy: 65.85 Val accuracy: 43.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 6/100 Step: 650 Loss: 1.3753 Val Loss: 1.7106\n",
            "Train accuracy: 73.52 Val accuracy: 46.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 7/100 Step: 780 Loss: 1.4540 Val Loss: 1.7033\n",
            "Train accuracy: 76.53 Val accuracy: 47.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 8/100 Step: 910 Loss: 1.3744 Val Loss: 1.6982\n",
            "Train accuracy: 84.37 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 9/100 Step: 1040 Loss: 1.3167 Val Loss: 1.6904\n",
            "Train accuracy: 90.53 Val accuracy: 48.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 10/100 Step: 1170 Loss: 1.2605 Val Loss: 1.6809\n",
            "Train accuracy: 93.36 Val accuracy: 51.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 11/100 Step: 1300 Loss: 1.2159 Val Loss: 1.6732\n",
            "Train accuracy: 94.70 Val accuracy: 51.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 12/100 Step: 1430 Loss: 1.2110 Val Loss: 1.6811\n",
            "Train accuracy: 95.73 Val accuracy: 50.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 13/100 Step: 1560 Loss: 1.2068 Val Loss: 1.6717\n",
            "Train accuracy: 96.48 Val accuracy: 50.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 15/100 Step: 1690 Loss: 1.2310 Val Loss: 1.6725\n",
            "Train accuracy: 96.20 Val accuracy: 50.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 16/100 Step: 1820 Loss: 1.2112 Val Loss: 1.6758\n",
            "Train accuracy: 97.30 Val accuracy: 49.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 17/100 Step: 1950 Loss: 1.1937 Val Loss: 1.6642\n",
            "Train accuracy: 97.87 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 18/100 Step: 2080 Loss: 1.2093 Val Loss: 1.6672\n",
            "Train accuracy: 97.65 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 19/100 Step: 2210 Loss: 1.2263 Val Loss: 1.6630\n",
            "Train accuracy: 98.16 Val accuracy: 50.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 20/100 Step: 2340 Loss: 1.2100 Val Loss: 1.6606\n",
            "Train accuracy: 98.10 Val accuracy: 51.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 21/100 Step: 2470 Loss: 1.1694 Val Loss: 1.6594\n",
            "Train accuracy: 98.83 Val accuracy: 51.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 22/100 Step: 2600 Loss: 1.2067 Val Loss: 1.6609\n",
            "Train accuracy: 98.38 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 23/100 Step: 2730 Loss: 1.1684 Val Loss: 1.6580\n",
            "Train accuracy: 98.49 Val accuracy: 51.33\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 24/100 Step: 2860 Loss: 1.2266 Val Loss: 1.6582\n",
            "Train accuracy: 98.44 Val accuracy: 51.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 25/100 Step: 2990 Loss: 1.2259 Val Loss: 1.6576\n",
            "Train accuracy: 98.49 Val accuracy: 51.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 26/100 Step: 3120 Loss: 1.1679 Val Loss: 1.6571\n",
            "Train accuracy: 98.55 Val accuracy: 51.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 28/100 Step: 3250 Loss: 1.1677 Val Loss: 1.6603\n",
            "Train accuracy: 99.40 Val accuracy: 51.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 29/100 Step: 3380 Loss: 1.1863 Val Loss: 1.6573\n",
            "Train accuracy: 98.10 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 30/100 Step: 3510 Loss: 1.1670 Val Loss: 1.6583\n",
            "Train accuracy: 98.87 Val accuracy: 51.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 31/100 Step: 3640 Loss: 1.1676 Val Loss: 1.6565\n",
            "Train accuracy: 98.95 Val accuracy: 51.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 32/100 Step: 3770 Loss: 1.1674 Val Loss: 1.6544\n",
            "Train accuracy: 98.92 Val accuracy: 51.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 33/100 Step: 3900 Loss: 1.1669 Val Loss: 1.6551\n",
            "Train accuracy: 98.73 Val accuracy: 51.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 34/100 Step: 4030 Loss: 1.1679 Val Loss: 1.6553\n",
            "Train accuracy: 98.83 Val accuracy: 51.47\n",
            "\n",
            "----------\n",
            "saving model .....\n",
            "----------\n",
            "\n",
            "Epoch: 35/100 Step: 4160 Loss: 1.1666 Val Loss: 1.6532\n",
            "Train accuracy: 98.75 Val accuracy: 51.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 36/100 Step: 4290 Loss: 1.1667 Val Loss: 1.6543\n",
            "Train accuracy: 99.04 Val accuracy: 51.60\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 37/100 Step: 4420 Loss: 1.1665 Val Loss: 1.6550\n",
            "Train accuracy: 99.06 Val accuracy: 51.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 38/100 Step: 4550 Loss: 1.1857 Val Loss: 1.6546\n",
            "Train accuracy: 98.93 Val accuracy: 51.73\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 39/100 Step: 4680 Loss: 1.1670 Val Loss: 1.6550\n",
            "Train accuracy: 98.98 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 41/100 Step: 4810 Loss: 1.1666 Val Loss: 1.6560\n",
            "Train accuracy: 98.80 Val accuracy: 51.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 42/100 Step: 4940 Loss: 1.1868 Val Loss: 1.6545\n",
            "Train accuracy: 98.90 Val accuracy: 51.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 43/100 Step: 5070 Loss: 1.1849 Val Loss: 1.6545\n",
            "Train accuracy: 98.87 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 44/100 Step: 5200 Loss: 1.1856 Val Loss: 1.6543\n",
            "Train accuracy: 99.15 Val accuracy: 51.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 45/100 Step: 5330 Loss: 1.1664 Val Loss: 1.6547\n",
            "Train accuracy: 99.16 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 46/100 Step: 5460 Loss: 1.1663 Val Loss: 1.6556\n",
            "Train accuracy: 99.00 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 47/100 Step: 5590 Loss: 1.1866 Val Loss: 1.6546\n",
            "Train accuracy: 99.00 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 48/100 Step: 5720 Loss: 1.1664 Val Loss: 1.6541\n",
            "Train accuracy: 99.20 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 49/100 Step: 5850 Loss: 1.1850 Val Loss: 1.6550\n",
            "Train accuracy: 99.07 Val accuracy: 51.20\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 50/100 Step: 5980 Loss: 1.1665 Val Loss: 1.6542\n",
            "Train accuracy: 99.10 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 51/100 Step: 6110 Loss: 1.1663 Val Loss: 1.6537\n",
            "Train accuracy: 99.09 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 52/100 Step: 6240 Loss: 1.2039 Val Loss: 1.6537\n",
            "Train accuracy: 99.08 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 54/100 Step: 6370 Loss: 1.1663 Val Loss: 1.6530\n",
            "Train accuracy: 99.80 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 55/100 Step: 6500 Loss: 1.1662 Val Loss: 1.6537\n",
            "Train accuracy: 99.60 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 56/100 Step: 6630 Loss: 1.1850 Val Loss: 1.6533\n",
            "Train accuracy: 99.20 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 57/100 Step: 6760 Loss: 1.1663 Val Loss: 1.6530\n",
            "Train accuracy: 99.00 Val accuracy: 50.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 58/100 Step: 6890 Loss: 1.1662 Val Loss: 1.6527\n",
            "Train accuracy: 99.00 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 59/100 Step: 7020 Loss: 1.1662 Val Loss: 1.6527\n",
            "Train accuracy: 98.90 Val accuracy: 51.33\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 60/100 Step: 7150 Loss: 1.1661 Val Loss: 1.6524\n",
            "Train accuracy: 99.20 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 61/100 Step: 7280 Loss: 1.1847 Val Loss: 1.6525\n",
            "Train accuracy: 99.20 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 62/100 Step: 7410 Loss: 1.1662 Val Loss: 1.6530\n",
            "Train accuracy: 99.22 Val accuracy: 51.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 63/100 Step: 7540 Loss: 1.1847 Val Loss: 1.6515\n",
            "Train accuracy: 99.18 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 64/100 Step: 7670 Loss: 1.1660 Val Loss: 1.6520\n",
            "Train accuracy: 99.22 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 65/100 Step: 7800 Loss: 1.1661 Val Loss: 1.6533\n",
            "Train accuracy: 99.20 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 67/100 Step: 7930 Loss: 1.2039 Val Loss: 1.6534\n",
            "Train accuracy: 99.00 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 68/100 Step: 8060 Loss: 1.1859 Val Loss: 1.6526\n",
            "Train accuracy: 99.20 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 69/100 Step: 8190 Loss: 1.1660 Val Loss: 1.6537\n",
            "Train accuracy: 99.27 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 70/100 Step: 8320 Loss: 1.1660 Val Loss: 1.6543\n",
            "Train accuracy: 99.35 Val accuracy: 49.87\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 71/100 Step: 8450 Loss: 1.1661 Val Loss: 1.6534\n",
            "Train accuracy: 99.32 Val accuracy: 50.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 72/100 Step: 8580 Loss: 1.1858 Val Loss: 1.6523\n",
            "Train accuracy: 99.33 Val accuracy: 50.40\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 73/100 Step: 8710 Loss: 1.2034 Val Loss: 1.6523\n",
            "Train accuracy: 99.37 Val accuracy: 50.13\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 74/100 Step: 8840 Loss: 1.1659 Val Loss: 1.6524\n",
            "Train accuracy: 99.25 Val accuracy: 50.00\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 75/100 Step: 8970 Loss: 1.1661 Val Loss: 1.6521\n",
            "Train accuracy: 99.33 Val accuracy: 50.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 76/100 Step: 9100 Loss: 1.1659 Val Loss: 1.6526\n",
            "Train accuracy: 99.28 Val accuracy: 50.27\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 77/100 Step: 9230 Loss: 1.2051 Val Loss: 1.6517\n",
            "Train accuracy: 99.33 Val accuracy: 51.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 78/100 Step: 9360 Loss: 1.1659 Val Loss: 1.6516\n",
            "Train accuracy: 99.30 Val accuracy: 50.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 80/100 Step: 9490 Loss: 1.1660 Val Loss: 1.6497\n",
            "Train accuracy: 99.00 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 81/100 Step: 9620 Loss: 1.1659 Val Loss: 1.6507\n",
            "Train accuracy: 99.00 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 82/100 Step: 9750 Loss: 1.1849 Val Loss: 1.6518\n",
            "Train accuracy: 99.20 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 83/100 Step: 9880 Loss: 1.1658 Val Loss: 1.6502\n",
            "Train accuracy: 99.35 Val accuracy: 50.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 84/100 Step: 10010 Loss: 1.1858 Val Loss: 1.6508\n",
            "Train accuracy: 99.40 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 85/100 Step: 10140 Loss: 1.1659 Val Loss: 1.6512\n",
            "Train accuracy: 99.20 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 86/100 Step: 10270 Loss: 1.1659 Val Loss: 1.6497\n",
            "Train accuracy: 99.37 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 87/100 Step: 10400 Loss: 1.1658 Val Loss: 1.6516\n",
            "Train accuracy: 99.10 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 88/100 Step: 10530 Loss: 1.1659 Val Loss: 1.6509\n",
            "Train accuracy: 99.29 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 89/100 Step: 10660 Loss: 1.2043 Val Loss: 1.6508\n",
            "Train accuracy: 99.32 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 90/100 Step: 10790 Loss: 1.1844 Val Loss: 1.6507\n",
            "Train accuracy: 99.35 Val accuracy: 50.53\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 91/100 Step: 10920 Loss: 1.1658 Val Loss: 1.6507\n",
            "Train accuracy: 99.35 Val accuracy: 50.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 93/100 Step: 11050 Loss: 1.1659 Val Loss: 1.6507\n",
            "Train accuracy: 99.40 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 94/100 Step: 11180 Loss: 1.1859 Val Loss: 1.6499\n",
            "Train accuracy: 99.20 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 95/100 Step: 11310 Loss: 1.1658 Val Loss: 1.6499\n",
            "Train accuracy: 99.47 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 96/100 Step: 11440 Loss: 1.1658 Val Loss: 1.6495\n",
            "Train accuracy: 99.25 Val accuracy: 50.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 97/100 Step: 11570 Loss: 1.1658 Val Loss: 1.6499\n",
            "Train accuracy: 99.56 Val accuracy: 50.93\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 98/100 Step: 11700 Loss: 1.1659 Val Loss: 1.6496\n",
            "Train accuracy: 99.50 Val accuracy: 51.07\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 99/100 Step: 11830 Loss: 1.1658 Val Loss: 1.6496\n",
            "Train accuracy: 99.46 Val accuracy: 50.67\n",
            "\n",
            "----------\n",
            "----------\n",
            "\n",
            "Epoch: 100/100 Step: 11960 Loss: 1.1846 Val Loss: 1.6496\n",
            "Train accuracy: 99.40 Val accuracy: 50.80\n",
            "\n",
            "----------\n",
            "Training complete in 13m 55s\n",
            "Best val Acc: 51.866667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ngx9VdyZJnE",
        "colab_type": "code",
        "outputId": "1d5f674a-1703-433d-9d63-00e11979b646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "net.load_state_dict(best_model_wts)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r32cZez_qkIt",
        "colab_type": "text"
      },
      "source": [
        "## Testing the model on test dataset ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Dz1kk58EVOt",
        "colab_type": "code",
        "outputId": "c708a35a-8c8b-42fc-cc2b-a2646297d9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "test_losses = [] # for tracking loss\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "y_true = []\n",
        "\n",
        "y_probs = []\n",
        "\n",
        "y_pred = []\n",
        "\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "net.eval()\n",
        "\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    # get predicted outputs\n",
        "    inputs = inputs.type(torch.LongTensor)\n",
        "    probs = net(inputs.to(device))\n",
        "    \n",
        "    # getting the index of output tensors with max values\n",
        "    _, classes = torch.max(probs.data, 1)\n",
        "    \n",
        "    \n",
        "    y_true += labels.cpu().numpy().tolist()\n",
        "    y_probs += classes.cpu().numpy().tolist()\n",
        "    y_pred += probs.cpu().detach().tolist()\n",
        "    \n",
        "    \n",
        "    # for calculating accuracy\n",
        "    total += labels.size(0)\n",
        "    correct += (classes == labels).sum().item() # comparing predictions to true label\n",
        "\n",
        "    \n",
        "    test_loss = criterion(probs, labels)\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))    \n",
        "print('Accuracy of the network on the test data : {:.3f} %'.format((correct / total) * 100))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.528\n",
            "Accuracy of the network on the test data : 63.733 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXXX14M0sBMw",
        "colab_type": "text"
      },
      "source": [
        "## functions for analysis of model ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "551pCCuAoYeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm =  metrics.confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the da\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXjVHFKOKjGC",
        "colab_type": "code",
        "outputId": "6b4775c9-349c-4139-9c39-137f21291b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "! pip3 install scikit-plot\n",
        "import scikitplot as skplt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.6/dist-packages (0.3.7)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.21.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.13.2)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (3.0.3)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->scikit-plot) (1.16.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.0->scikit-plot) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G-VNBpJR9RD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from  sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "def class_report(y_true, y_pred, y_score=None, average='micro'):\n",
        "    if y_true.shape != y_pred.shape:\n",
        "        print(\"Error! y_true %s is not the same shape as y_pred %s\" % (\n",
        "              y_true.shape,\n",
        "              y_pred.shape)\n",
        "        )\n",
        "        return\n",
        "\n",
        "    lb = LabelBinarizer()\n",
        "\n",
        "    if len(y_true.shape) == 1:\n",
        "        lb.fit(y_true)\n",
        "\n",
        "    #Value counts of predictions\n",
        "    labels, cnt = np.unique(\n",
        "        y_pred,\n",
        "        return_counts=True)\n",
        "    n_classes = len(labels)\n",
        "    pred_cnt = pd.Series(cnt, index=labels)\n",
        "\n",
        "    metrics_summary = precision_recall_fscore_support(\n",
        "            y_true=y_true,\n",
        "            y_pred=y_pred,\n",
        "            labels=labels)\n",
        "\n",
        "    avg = list(precision_recall_fscore_support(\n",
        "            y_true=y_true, \n",
        "            y_pred=y_pred,\n",
        "            average='weighted'))\n",
        "\n",
        "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']\n",
        "    class_report_df = pd.DataFrame(\n",
        "        list(metrics_summary),\n",
        "        index=metrics_sum_index,\n",
        "        columns=labels)\n",
        "\n",
        "    support = class_report_df.loc['support']\n",
        "    total = support.sum() \n",
        "    class_report_df['avg / total'] = avg[:-1] + [total]\n",
        "\n",
        "    class_report_df = class_report_df.T\n",
        "    class_report_df['pred'] = pred_cnt\n",
        "    class_report_df['pred'].iloc[-1] = total\n",
        "\n",
        "    if not (y_score is None):\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "        for label_it, label in enumerate(labels):\n",
        "            fpr[label], tpr[label], _ = roc_curve(\n",
        "                (y_true == label).astype(int), \n",
        "                y_score[:, label_it])\n",
        "\n",
        "            roc_auc[label] = auc(fpr[label], tpr[label])\n",
        "\n",
        "        if average == 'micro':\n",
        "            if n_classes <= 2:\n",
        "                fpr[\"avg / total\"], tpr[\"avg / total\"], _ = roc_curve(\n",
        "                    lb.transform(y_true).ravel(), \n",
        "                    y_score[:, 1].ravel())\n",
        "            else:\n",
        "                fpr[\"avg / total\"], tpr[\"avg / total\"], _ = roc_curve(\n",
        "                        lb.transform(y_true).ravel(), \n",
        "                        y_score.ravel())\n",
        "\n",
        "            roc_auc[\"avg / total\"] = auc(\n",
        "                fpr[\"avg / total\"], \n",
        "                tpr[\"avg / total\"])\n",
        "\n",
        "        elif average == 'macro':\n",
        "            # First aggregate all false positive rates\n",
        "            all_fpr = np.unique(np.concatenate([\n",
        "                fpr[i] for i in labels]\n",
        "            ))\n",
        "\n",
        "            # Then interpolate all ROC curves at this points\n",
        "            mean_tpr = np.zeros_like(all_fpr)\n",
        "            for i in labels:\n",
        "                mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "            # Finally average it and compute AUC\n",
        "            mean_tpr /= n_classes\n",
        "\n",
        "            fpr[\"macro\"] = all_fpr\n",
        "            tpr[\"macro\"] = mean_tpr\n",
        "\n",
        "            roc_auc[\"avg / total\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "        class_report_df['AUC'] = pd.Series(roc_auc)\n",
        "\n",
        "    return class_report_df, fpr, tpr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOsO1e40rXlV",
        "colab_type": "text"
      },
      "source": [
        "# Analysis of Model #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSjAdiSca_bj",
        "colab_type": "code",
        "outputId": "d413d0f8-0645-4ebc-bf2c-76aa8d397dee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        }
      },
      "source": [
        "y_true = np.array(y_true)\n",
        "\n",
        "y_probs = np.array(y_probs)\n",
        "\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "\n",
        "report_with_auc , fpr , tpr = class_report(y_true=y_true, y_pred=y_probs, y_score=y_pred)\n",
        "\n",
        "print(report_with_auc)\n",
        "\n",
        "plot_confusion_matrix(y_true, y_probs, classes=emotions, normalize=False, title='confusion matrix')\n",
        "\n",
        "fig2 = plot_confusion_matrix(y_true, y_probs, classes=emotions, normalize=False, title='confusion matrix')\n",
        "fig2 = fig2.get_figure()\n",
        "\n",
        "fig2.savefig('confusion.png', dpi=1440)\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score  support   pred       AUC\n",
            "0             0.750000  0.783784  0.766520    111.0  116.0  0.947454\n",
            "1             0.762376  0.706422  0.733333    109.0  101.0  0.922054\n",
            "2             0.546218  0.590909  0.567686    110.0  119.0  0.890128\n",
            "3             0.675214  0.738318  0.705357    107.0  117.0  0.920001\n",
            "4             0.564356  0.542857  0.553398    105.0  101.0  0.864673\n",
            "5             0.483051  0.542857  0.511211    105.0  118.0  0.848682\n",
            "6             0.717949  0.543689  0.618785    103.0   78.0  0.906094\n",
            "avg / total   0.643477  0.637333  0.637939    750.0  750.0  0.902960\n",
            "Confusion matrix, without normalization\n",
            "Confusion matrix, without normalization\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAEYCAYAAADFzZobAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmg6Z8WVkZDQdMuPLyMhoOvwHPAcEJ5F017gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAEYCAYAAADFzZobAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmg6Z8WVkZDQdMuPLyMhoOvwHPAcEJ5F017gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMTtLaZqf-lO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "25804e9d-7df3-46c8-80c8-1c92b7c8db3c"
      },
      "source": [
        "fig = skplt.metrics.plot_roc_curve(y_true, y_pred)\n",
        "fig = fig.get_figure()\n",
        "\n",
        "fig.savefig('roc.png', dpi=144)\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-35dc14e7c843>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roc.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m144\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF3HI5e9q4Ba",
        "colab_type": "text"
      },
      "source": [
        "## Testing model on custom string ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cvuz7fikF4qb",
        "colab_type": "code",
        "outputId": "597ace8b-0800-4781-a15e-e08ce5d2709c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# testing on custom dataset\n",
        "\n",
        "from string import punctuation\n",
        "\n",
        "# for tranforming the string into tokens\n",
        "\n",
        "def tokenize_text(test_text):\n",
        "    test_text = test_text.lower() # lowercase\n",
        "    \n",
        "    # get rid of punctuation\n",
        "    test_text = ''.join([c for c in test_text if c not in punctuation])\n",
        "\n",
        "    # splitting the lines into words for tokenization\n",
        "    test_words = test_text.split()\n",
        "\n",
        "    # tokenizing the text\n",
        "    test_ints = []\n",
        "    test_ints.append([vocab_to_int[word] for word in test_words])\n",
        "\n",
        "    return test_ints\n",
        "  \n",
        "# test string\n",
        "test_text = \"I am very angry and sad !! :)\"\n",
        "\n",
        "\n",
        "def predict(net, test_text, sequence_length):\n",
        "    \n",
        "    net.eval()\n",
        "    \n",
        "    # tokenize text\n",
        "    test_ints = tokenize_text(test_text)\n",
        "    \n",
        "    # pad tokenized sequence\n",
        "    seq_length=sequence_length\n",
        "    features = pad_features(test_ints, seq_length)\n",
        "    \n",
        "    # convering the array to tensor to pass into the model\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "    \n",
        "    batch_size = feature_tensor.size(0) # number of strings to test\n",
        "\n",
        "    \n",
        "    if(train_on_gpu):\n",
        "        feature_tensor = feature_tensor.to(device)\n",
        "    \n",
        "    # get the output from the model\n",
        "    probs = net(feature_tensor)\n",
        "    print(probs.cpu().detach().numpy())\n",
        "    print(emotions)\n",
        "\n",
        "\n",
        "    print(\"{} --> {}\".format(test_text, emotions[classes.cpu().numpy()[0]]))\n",
        "\n",
        "    \n",
        "predict(net, test_text, sequence_length=64)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.77249555e-03 2.85694987e-05 1.21140555e-01 8.72912884e-01\n",
            "  1.76192683e-04 1.96318980e-03 6.12625581e-06]]\n",
            "['joy', 'fear', 'anger', 'sadness', 'disgust', 'shame', 'guilt']\n",
            "I am very angry and sad !! :) --> shame\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpIBhGb5Lvm5",
        "colab_type": "code",
        "outputId": "9b02fbf6-c82d-46fe-c273-9489b4a3de59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "!zip -r /content/logs_2.zip /content/logs"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/logs/ (stored 0%)\n",
            "  adding: content/logs/lr_1E-02/ (stored 0%)\n",
            "  adding: content/logs/lr_1E-02/events.out.tfevents.1559801396.583c35691b4c (deflated 70%)\n",
            "  adding: content/logs/lr_1E-02/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/logs/lr_5E-04/ (stored 0%)\n",
            "  adding: content/logs/lr_5E-04/events.out.tfevents.1559800841.583c35691b4c (deflated 70%)\n",
            "  adding: content/logs/lr_5E-04/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/logs/lr_1E-03/ (stored 0%)\n",
            "  adding: content/logs/lr_1E-03/events.out.tfevents.1559800980.583c35691b4c (deflated 70%)\n",
            "  adding: content/logs/lr_1E-03/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/logs/lr_2E-03/ (stored 0%)\n",
            "  adding: content/logs/lr_2E-03/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/logs/lr_2E-03/events.out.tfevents.1559801119.583c35691b4c (deflated 70%)\n",
            "  adding: content/logs/lr_5E-03/ (stored 0%)\n",
            "  adding: content/logs/lr_5E-03/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/logs/lr_5E-03/events.out.tfevents.1559801257.583c35691b4c (deflated 70%)\n",
            "  adding: content/logs/lr_1E-04/ (stored 0%)\n",
            "  adding: content/logs/lr_1E-04/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/logs/lr_1E-04/events.out.tfevents.1559800703.583c35691b4c (deflated 70%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13RTEblFfEhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(net.state_dict(), 'model_sentiment_analysis_CNN_custom_embedding.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4tl1WNwfJps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFRZOmOSfSBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou-r9AFMRGw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWtTTnwxSFet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}